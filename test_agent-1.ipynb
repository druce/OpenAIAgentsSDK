{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d549de08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import dotenv\n",
    "import logging\n",
    "import json\n",
    "import yaml\n",
    "import time\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "\n",
    "import pydantic\n",
    "from pydantic import BaseModel, Field, RootModel\n",
    "from typing import Dict, TypedDict, Type, List, Optional, Any\n",
    "from dataclasses import dataclass, field\n",
    "from enum import Enum\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import openai\n",
    "from openai import AsyncOpenAI\n",
    "\n",
    "import agents\n",
    "from agents.exceptions import InputGuardrailTripwireTriggered\n",
    "from agents import (Agent, Runner, Tool, ModelSettings, FunctionTool, InputGuardrail, GuardrailFunctionOutput, \n",
    "                    set_default_openai_api, set_default_openai_client\n",
    "                   )\n",
    "\n",
    "from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type\n",
    "\n",
    "from prompt_loader import PromptLoader\n",
    "from log_handler import SQLiteLogHandler, setup_sqlite_logging, sanitize_error_for_logging\n",
    "from utilities import (StepStatus, WorkflowStatus, \n",
    "                       get_workflow_status_report, print_workflow_summary, create_news_dataframe,    \n",
    "                      )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cea80dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI:            1.101.0\n",
      "OpenAI Agents SDK  0.2.9\n",
      "Pydantic           2.11.7\n"
     ]
    }
   ],
   "source": [
    "print(f\"OpenAI:            {openai.__version__}\")\n",
    "print(f\"OpenAI Agents SDK  {agents.__version__}\")\n",
    "print(f\"Pydantic           {pydantic.__version__}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b742842e",
   "metadata": {},
   "source": [
    "# Basic usage\n",
    "- run a prompt using agents\n",
    "- route through Portkey for observability\n",
    "- save logs\n",
    "- link to openai for traces and evals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "153c333d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPENAI_BASE_URL = http://localhost:8787/v1\n",
      "OPENAI_DEFAULT_HEADERS = {\"x-portkey-provider\": \"openai\"}\n"
     ]
    }
   ],
   "source": [
    "# load environment variables including OPENAI_API_KEY\n",
    "# important - for portkey\n",
    "# OPENAI_BASE_URL=\"http://localhost:8787/v1\"\n",
    "# OPENAI_DEFAULT_HEADERS='{\"x-portkey-provider\": \"openai\"}'\n",
    "# launch proxy service https://portkey.ai/docs/product/enterprise-offering/components\n",
    "# npx @portkey-ai/gateway\n",
    "# could point to a database with a portkey_config.yaml\n",
    "# logging:\n",
    "#   sink: sql\n",
    "#   database_url: postgres://user:password@localhost:5432/portkey\n",
    "# npx @portkey-ai/gateway --portkey_config.yaml\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "# to run async in jupyter notebook\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# verbose console logging if something doesn't work\n",
    "# logging.basicConfig(level=logging.DEBUG)\n",
    "# openai_logger = logging.getLogger(\"openai\")\n",
    "# openai_logger.setLevel(logging.DEBUG)\n",
    "\n",
    "# needed for portkey - responses API is persistent connection-oriented and seeems to not work\n",
    "set_default_openai_api(\"chat_completions\")\n",
    "\n",
    "print(\"OPENAI_BASE_URL =\", os.getenv(\"OPENAI_BASE_URL\"))\n",
    "print(\"OPENAI_DEFAULT_HEADERS =\", os.getenv(\"OPENAI_DEFAULT_HEADERS\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "686ed01b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14:03:46 | NewsletterAgent.newsletter_agent | INFO | Test info message\n",
      "14:03:46 | NewsletterAgent.newsletter_agent | WARNING | Test warning message\n",
      "14:03:46 | NewsletterAgent.newsletter_agent | ERROR | Test error message\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'log with some bad stuff for the filter: [API_KEY_REDACTED]'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def setup_logging(session_id: str = \"default\", db_path: str = \"agent_logs.db\") -> logging.Logger:\n",
    "    \"\"\"Set up logging to console and SQLite database.\"\"\"\n",
    "\n",
    "    # Create logger\n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "    \n",
    "    logger = logging.getLogger(f\"NewsletterAgent.{session_id}\")\n",
    "    logger.setLevel(logging.INFO)\n",
    "\n",
    "    # Clear any existing handlers\n",
    "    logger.handlers.clear()\n",
    "\n",
    "    # Console handler\n",
    "    console_handler = logging.StreamHandler()\n",
    "    console_handler.setLevel(logging.INFO)\n",
    "    console_formatter = logging.Formatter(\n",
    "        '%(asctime)s | %(name)s | %(levelname)s | %(message)s',\n",
    "        datefmt='%H:%M:%S'\n",
    "    )\n",
    "    console_handler.setFormatter(console_formatter)\n",
    "\n",
    "    # SQLite handler\n",
    "    sqlite_handler = SQLiteLogHandler(db_path)\n",
    "    sqlite_handler.setLevel(logging.INFO)\n",
    "    sqlite_formatter = logging.Formatter('%(message)s')\n",
    "    sqlite_handler.setFormatter(sqlite_formatter)\n",
    "\n",
    "    # Add handlers to logger\n",
    "    logger.addHandler(console_handler)\n",
    "    logger.addHandler(sqlite_handler)\n",
    "\n",
    "    # Prevent propagation to root logger\n",
    "    logger.propagate = False\n",
    "\n",
    "    return logger\n",
    "\n",
    "logger = setup_logging(\"newsletter_agent\", \"test_logs.db\")\n",
    "\n",
    "# Log some test messages\n",
    "logger.info(\"Test info message\", extra={\n",
    "    'step_name': 'test_step',\n",
    "    'agent_session': 'demo_session'\n",
    "})\n",
    "\n",
    "logger.warning(\"Test warning message\", extra={\n",
    "    'step_name': 'test_step',\n",
    "    'agent_session': 'demo_session'\n",
    "})\n",
    "\n",
    "logger.error(\"Test error message\", extra={\n",
    "    'step_name': 'error_step',\n",
    "    'agent_session': 'demo_session'\n",
    "})\n",
    "\n",
    "sanitize_error_for_logging(\"log with some bad stuff for the filter: sk-proj-123456789012345678901234567890123456789012345678\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8b4cb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = AsyncOpenAI(\n",
    "    base_url=os.getenv(\"OPENAI_BASE_URL\"),\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "    default_headers=json.loads(os.getenv(\"OPENAI_DEFAULT_HEADERS\")),\n",
    ")\n",
    "\n",
    "# set the client globally\n",
    "set_default_openai_client(client)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86f975ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/traces/ingest \"HTTP/1.1 204 No Content\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8787/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ah — the classic. First: do you mean a European or an African swallow?\n",
      "\n",
      "- European swallow (Hirundo rustica), unladen, cruises at roughly 11 m/s — about 24–25 mph (≈39–40 km/h).  \n",
      "- “African swallow” is a group of different species; speeds vary but are generally in the same ballpark (about 9–12 m/s) depending on species and conditions.\n",
      "\n",
      "So: an unladen European swallow ≈ 11 m/s. And no — it still can’t carry a coconut.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/traces/ingest \"HTTP/1.1 204 No Content\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/traces/ingest \"HTTP/1.1 204 No Content\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/traces/ingest \"HTTP/1.1 204 No Content\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/traces/ingest \"HTTP/1.1 204 No Content\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/traces/ingest \"HTTP/1.1 204 No Content\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/traces/ingest \"HTTP/1.1 204 No Content\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/traces/ingest \"HTTP/1.1 204 No Content\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/traces/ingest \"HTTP/1.1 204 No Content\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/traces/ingest \"HTTP/1.1 204 No Content\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/traces/ingest \"HTTP/1.1 204 No Content\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/traces/ingest \"HTTP/1.1 204 No Content\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/traces/ingest \"HTTP/1.1 204 No Content\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/traces/ingest \"HTTP/1.1 204 No Content\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/traces/ingest \"HTTP/1.1 204 No Content\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/traces/ingest \"HTTP/1.1 204 No Content\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/traces/ingest \"HTTP/1.1 204 No Content\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/traces/ingest \"HTTP/1.1 204 No Content\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/traces/ingest \"HTTP/1.1 204 No Content\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/traces/ingest \"HTTP/1.1 204 No Content\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/traces/ingest \"HTTP/1.1 204 No Content\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/traces/ingest \"HTTP/1.1 204 No Content\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/traces/ingest \"HTTP/1.1 204 No Content\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/traces/ingest \"HTTP/1.1 204 No Content\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/traces/ingest \"HTTP/1.1 204 No Content\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/traces/ingest \"HTTP/1.1 204 No Content\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/traces/ingest \"HTTP/1.1 204 No Content\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/traces/ingest \"HTTP/1.1 204 No Content\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/traces/ingest \"HTTP/1.1 204 No Content\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/traces/ingest \"HTTP/1.1 204 No Content\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/traces/ingest \"HTTP/1.1 204 No Content\"\n"
     ]
    }
   ],
   "source": [
    "# run a simple query through portkey\n",
    "# can see traces in openai https://platform.openai.com/logs?api=traces\n",
    "# potentially set up evals - https://platform.openai.com/evaluations\n",
    "\n",
    "myagent = Agent(\n",
    "    name=\"Swallow Expert\",\n",
    "    instructions=\"You are an expert on airspeed velocities of swallows. Answer questions about swallow flight speeds with authority and humor when appropriate.\",\n",
    "    model=\"gpt-5-mini\",\n",
    "    # these below seem to be being deprecated, you probably have to use old chat API directly on eg gpt-4o for logprobs\n",
    "    # model_settings=ModelSettings(temperature=0.0, logprobs=1, top_logprobs=1)\n",
    ")\n",
    "\n",
    "myresult = await Runner.run(myagent, \"What is the airspeed velocity of an unladen swallow?\")\n",
    "print(myresult.final_output)    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1194bf7",
   "metadata": {},
   "source": [
    "# More advanced usage\n",
    "- Prompt Management\n",
    "- Structured JSON outputs, enables validation and safe passing downstream over long pipelines\n",
    "- Map prompts to larger data sets asynchronously (e.g. send parallel batches of 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5cfea49d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10:44:10 | NewsletterAgent.newsletter_agent | INFO | Show available prompts\n",
      "10:44:11 | NewsletterAgent.newsletter_agent | INFO | Load a prompt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a content-classification assistant that labels news headlines as AI-related or not.\n",
      "Return JSON that matches the provided schema\n",
      "\n",
      "A headline is AI-related if it mentions (explicitly or implicitly):\n",
      "- Core AI models: machine learning, neural / deep / transformer networks\n",
      "- AI Applications: computer vision, NLP, robotics, autonomous driving, generative media\n",
      "- AI hardware, GPU chip supply, AI data centers and infrastructure\n",
      "- Companies or labs known for AI: OpenAI, DeepMind, Anthropic, xAI, NVIDIA, etc.\n",
      "- AI models & products: GPT-5, Gemini, Claude, Midjourney, DeepSeek, etc.\n",
      "- New AI products and AI integration into existing products/services\n",
      "- AI policy / ethics / safety / regulation / analysis\n",
      "- Research results related to AI\n",
      "- AI industry figures (Sam Altman, Demis Hassabis, Dario Amodei, etc.)\n",
      "- AI market and business developments, funding rounds, partnerships centered on AI\n",
      "- Any other news with a significant AI component\n",
      "\n",
      "Not AI-related: business software, crypto, non-AI tech, non-AI medical devices, and anything else.\n",
      "\n",
      "No markdown, no explanations, just the JSON. \n",
      "Classify the following headline(s): \n",
      "{input_str} \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10:44:12 | NewsletterAgent.newsletter_agent | INFO | Show prompt metadata\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_recommendations': ['gpt-4o-mini'], 'use_case': 'AI headline classification for news aggregation'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10:44:13 | NewsletterAgent.newsletter_agent | INFO | Format a prompt with input\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'system': 'You are a content-classification assistant that labels news headlines as AI-related or not.\\nReturn JSON that matches the provided schema\\n\\nA headline is AI-related if it mentions (explicitly or implicitly):\\n- Core AI models: machine learning, neural / deep / transformer networks\\n- AI Applications: computer vision, NLP, robotics, autonomous driving, generative media\\n- AI hardware, GPU chip supply, AI data centers and infrastructure\\n- Companies or labs known for AI: OpenAI, DeepMind, Anthropic, xAI, NVIDIA, etc.\\n- AI models & products: GPT-5, Gemini, Claude, Midjourney, DeepSeek, etc.\\n- New AI products and AI integration into existing products/services\\n- AI policy / ethics / safety / regulation / analysis\\n- Research results related to AI\\n- AI industry figures (Sam Altman, Demis Hassabis, Dario Amodei, etc.)\\n- AI market and business developments, funding rounds, partnerships centered on AI\\n- Any other news with a significant AI component\\n\\nNot AI-related: business software, crypto, non-AI tech, non-AI medical devices, and anything else.\\n\\nNo markdown, no explanations, just the JSON.', 'user': \"Classify the following headline(s): \\nAI Is Replacing Online Moderators, But It's Bad at the Job\"}\n"
     ]
    }
   ],
   "source": [
    "# get prompts from the prompt repository (the promptfoo yaml files)\n",
    "# langfuse probably a better enterprise option\n",
    "# prompt repository solution allows us to run evals, version prompts, improving performance over time\n",
    "\n",
    "logger.info(\"Show available prompts\")\n",
    "my_prompt_loader = PromptLoader()\n",
    "my_prompt_loader.list_available_prompts()\n",
    "\n",
    "prompt_name = 'headline_classifier_v1'\n",
    "prompt_dict = my_prompt_loader.load_prompt_by_name(prompt_name)\n",
    "time.sleep(1)\n",
    "\n",
    "logger.info(\"Load a prompt\")\n",
    "print(prompt_dict.get('system'), \"\")\n",
    "print(prompt_dict.get('user'), \"\")\n",
    "time.sleep(1)\n",
    "\n",
    "logger.info(\"Show prompt metadata\")\n",
    "prompt_metadata = my_prompt_loader.get_prompt_metadata(prompt_name)\n",
    "print(prompt_metadata)\n",
    "time.sleep(1)\n",
    "\n",
    "logger.info(\"Format a prompt with input\")\n",
    "print(my_prompt_loader.format_prompt(prompt_name, input_str=\"AI Is Replacing Online Moderators, But It's Bad at the Job\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f123315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output class for classifying headlines\n",
    "class ClassificationResult(BaseModel):\n",
    "    \"\"\"A single headline classification result\"\"\"\n",
    "    input_str: str = Field(description=\"The original headline text\")\n",
    "    output: bool = Field(description=\"Whether the headline is AI-related\")\n",
    "\n",
    "class ClassificationResultList(BaseModel):\n",
    "    \"\"\"List of ClassificationResult for batch processing\"\"\"\n",
    "    results_list: list[ClassificationResult] = Field(description=\"List of classification results\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3bc3c606",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = AsyncOpenAI(\n",
    "    base_url=os.getenv(\"OPENAI_BASE_URL\"),\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "    default_headers=json.loads(os.getenv(\"OPENAI_DEFAULT_HEADERS\")),\n",
    ")\n",
    "\n",
    "# set the client globally\n",
    "set_default_openai_client(client)\n",
    "\n",
    "class ClassifierAgent(Agent):\n",
    "    \"\"\"Agent for classifying headlines as AI-related or not\n",
    "    or more generally apply a prompt to a string for a classification according to an output type\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 system_prompt: str,\n",
    "                 user_prompt: str,\n",
    "                 output_type: Type[BaseModel],\n",
    "                 model: str,\n",
    "                 verbose: bool = False):\n",
    "        \"\"\"\n",
    "        Initialize the ClassifierAgent\n",
    "\n",
    "        Args:\n",
    "            system_prompt: The system prompt template to use\n",
    "            user_prompt: The user prompt template to use\n",
    "            output_type: Pydantic model class for structured output\n",
    "            verbose: Enable verbose logging\n",
    "        \"\"\"\n",
    "        super().__init__(\n",
    "            name=\"ClassifierAgent\",\n",
    "            model=model,\n",
    "            instructions=system_prompt,\n",
    "            output_type=output_type\n",
    "        )\n",
    "        self.system_prompt = system_prompt\n",
    "        self.user_prompt = user_prompt\n",
    "        self.verbose = verbose\n",
    "\n",
    "        if self.verbose:\n",
    "            logger.info(f\"\"\"Initialized ClassifierAgent:\n",
    "system_prompt:\n",
    "{self.system_prompt}\n",
    "user_prompt:\n",
    "{self.user_prompt}\n",
    "output_type:         {output_type.__name__}\n",
    "model:               {self.model}\n",
    "schema:              {json.dumps(output_type.model_json_schema(), indent=2)}\n",
    "\"\"\")\n",
    "    @retry(\n",
    "        retry=retry_if_exception_type((openai.APIConnectionError, \n",
    "                                       openai.APITimeoutError,\n",
    "                                       openai.InternalServerError)),\n",
    "        stop=stop_after_attempt(5),  # 5 attempts sufficient for classification\n",
    "        after=lambda retry_state: log(sanitize_error_for_logging(\n",
    "            f\"Attempt {retry_state.attempt_number}: {retry_state.outcome.exception()}, tag: {retry_state.args[1].get('tag', '')}\")),\n",
    "        wait=wait_exponential(multiplier=1, min=1, max=30),\n",
    "    )\n",
    "        \n",
    "    async def classify(self, input_str: str) -> Type[BaseModel]:\n",
    "        \"\"\"\n",
    "        Classify a single input or a string with multiple inputs to the specified type\n",
    "\n",
    "        Args:\n",
    "            input: The input text to classify\n",
    "\n",
    "        Returns:\n",
    "            The specified type\n",
    "        \"\"\"\n",
    "        user_message = self.user_prompt.format(input_str=input_str)\n",
    "        if self.verbose:\n",
    "            logger.info(f\"User message: {user_message}\")\n",
    "\n",
    "        results_list = await Runner.run(self, user_message)\n",
    "        if self.verbose:\n",
    "            logger.info(f\"Result: {results_list}\")\n",
    "        return results_list\n",
    "    \n",
    "    async def classify_batch(self, input_list: List[str], batch_size: int = 25,\n",
    "                             *, max_concurrency: int = 16, retries: int = 3\n",
    "                            ) -> Any:\n",
    "        \n",
    "        \"\"\"\n",
    "        Classify a list using paged, parallel calls to `self.classify()`,\n",
    "        preserving the original input order and validating page sizes.\n",
    "        \"\"\"\n",
    "        # Type must have a 'results_list' element\n",
    "        null_return = self.output_type(results_list=[])\n",
    "        if not input_list:\n",
    "            return null_return\n",
    "        \n",
    "        pages = [input_list[i:i+batch_size] \n",
    "                 for i in range(0, len(input_list), batch_size)]\n",
    "        sem = asyncio.Semaphore(max_concurrency)\n",
    "        logger.info(f\"Sending {len(pages)} batches with concurrency {max_concurrency}\")\n",
    "        \n",
    "        async def _guarded_classify(page_idx: int, items: List[str]) -> self.output_type:\n",
    "            for i in range(retries):\n",
    "                input_str = \"\\n\".join(items)\n",
    "                try:\n",
    "                    async with sem:\n",
    "                        result = await self.classify(input_str)\n",
    "                    res = result.final_output\n",
    "#                     print(type(res))\n",
    "#                     print(\"----\")\n",
    "#                     print(res)\n",
    "#                     print(\"----\")\n",
    "                    if not hasattr(res, \"results_list\"):\n",
    "                        raise ValueError(\"Bad structured output or missing 'results_list'.\")\n",
    "                    if not isinstance(res.results_list, list):\n",
    "                        raise ValueError(\"Structured output invalid 'results_list'.\")\n",
    "                    if len(res.results_list) != len(items):\n",
    "                        raise ValueError(\n",
    "                            f\"Page {page_idx}: count mismatch (got {len(res.results_list)} vs expected {len(items)}).\"\n",
    "                        )\n",
    "                    return (page_idx, res)\n",
    "                except Exception as e:\n",
    "                    last_exc = e\n",
    "                    logger.info(f\"[page {page_idx}] attempt {i+1}/{retries} failed: {e}\")\n",
    "                    if i < retries:\n",
    "                        await asyncio.sleep(2 ** i)  # 1s, 2s, 4s backoff\n",
    "                    \n",
    "            return page_idx, last_exc if last_exc else RuntimeError(f\"Unknown error on page {page_idx}\")\n",
    "        \n",
    "        tasks = [\n",
    "            asyncio.create_task(_guarded_classify(i, page))\n",
    "            for i, page in enumerate(pages)\n",
    "        ]\n",
    "        page_results = await asyncio.gather(*tasks)\n",
    "\n",
    "        # Reassemble in original order\n",
    "        flattened_results = []\n",
    "        for idx, res_or_exc in page_results:\n",
    "            if isinstance(res_or_exc, Exception):\n",
    "                raise res_or_exc\n",
    "            elif res_or_exc:\n",
    "                flattened_results.extend(res_or_exc.results_list)\n",
    "            else:\n",
    "                logger.info(f\"no results for page {idx}\")\n",
    "\n",
    "        final = self.output_type(results_list=flattened_results)\n",
    "        \n",
    "        # Final sanity check\n",
    "        if len(final.results_list) != len(input_list):\n",
    "            raise ValueError(f\"Final count mismatch: expected {len(input_list)} results, got {len(flattened.results_list)}.\")\n",
    "\n",
    "        return final        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8dd3de5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10:49:58 | NewsletterAgent.newsletter_agent | INFO | Initialized ClassifierAgent:\n",
      "system_prompt:\n",
      "You are a content-classification assistant that labels news headlines as AI-related or not.\n",
      "Return JSON that matches the provided schema\n",
      "\n",
      "A headline is AI-related if it mentions (explicitly or implicitly):\n",
      "- Core AI models: machine learning, neural / deep / transformer networks\n",
      "- AI Applications: computer vision, NLP, robotics, autonomous driving, generative media\n",
      "- AI hardware, GPU chip supply, AI data centers and infrastructure\n",
      "- Companies or labs known for AI: OpenAI, DeepMind, Anthropic, xAI, NVIDIA, etc.\n",
      "- AI models & products: GPT-5, Gemini, Claude, Midjourney, DeepSeek, etc.\n",
      "- New AI products and AI integration into existing products/services\n",
      "- AI policy / ethics / safety / regulation / analysis\n",
      "- Research results related to AI\n",
      "- AI industry figures (Sam Altman, Demis Hassabis, Dario Amodei, etc.)\n",
      "- AI market and business developments, funding rounds, partnerships centered on AI\n",
      "- Any other news with a significant AI component\n",
      "\n",
      "Not AI-related: business software, crypto, non-AI tech, non-AI medical devices, and anything else.\n",
      "\n",
      "No markdown, no explanations, just the JSON.\n",
      "user_prompt:\n",
      "Classify the following headline(s): \n",
      "{input_str}\n",
      "output_type:         ClassificationResult\n",
      "model:               gpt-5-mini\n",
      "schema:              {\n",
      "  \"description\": \"A single headline classification result\",\n",
      "  \"properties\": {\n",
      "    \"input_str\": {\n",
      "      \"description\": \"The original headline text\",\n",
      "      \"title\": \"Input Str\",\n",
      "      \"type\": \"string\"\n",
      "    },\n",
      "    \"output\": {\n",
      "      \"description\": \"Whether the headline is AI-related\",\n",
      "      \"title\": \"Output\",\n",
      "      \"type\": \"boolean\"\n",
      "    }\n",
      "  },\n",
      "  \"required\": [\n",
      "    \"input_str\",\n",
      "    \"output\"\n",
      "  ],\n",
      "  \"title\": \"ClassificationResult\",\n",
      "  \"type\": \"object\"\n",
      "}\n",
      "\n",
      "10:49:58 | NewsletterAgent.newsletter_agent | INFO | Initialized ClassifierAgent:\n",
      "system_prompt:\n",
      "You are a content-classification assistant that labels news headlines as AI-related or not.\n",
      "Return JSON that matches the provided schema\n",
      "\n",
      "A headline is AI-related if it mentions (explicitly or implicitly):\n",
      "- Core AI models: machine learning, neural / deep / transformer networks\n",
      "- AI Applications: computer vision, NLP, robotics, autonomous driving, generative media\n",
      "- AI hardware, GPU chip supply, AI data centers and infrastructure\n",
      "- Companies or labs known for AI: OpenAI, DeepMind, Anthropic, xAI, NVIDIA, etc.\n",
      "- AI models & products: GPT-5, Gemini, Claude, Midjourney, DeepSeek, etc.\n",
      "- New AI products and AI integration into existing products/services\n",
      "- AI policy / ethics / safety / regulation / analysis\n",
      "- Research results related to AI\n",
      "- AI industry figures (Sam Altman, Demis Hassabis, Dario Amodei, etc.)\n",
      "- AI market and business developments, funding rounds, partnerships centered on AI\n",
      "- Any other news with a significant AI component\n",
      "\n",
      "Not AI-related: business software, crypto, non-AI tech, non-AI medical devices, and anything else.\n",
      "\n",
      "No markdown, no explanations, just the JSON.\n",
      "user_prompt:\n",
      "Classify the following headline(s): \n",
      "{input_str}\n",
      "output_type:         ClassificationResult\n",
      "model:               gpt-5-mini\n",
      "schema:              {\n",
      "  \"description\": \"A single headline classification result\",\n",
      "  \"properties\": {\n",
      "    \"input_str\": {\n",
      "      \"description\": \"The original headline text\",\n",
      "      \"title\": \"Input Str\",\n",
      "      \"type\": \"string\"\n",
      "    },\n",
      "    \"output\": {\n",
      "      \"description\": \"Whether the headline is AI-related\",\n",
      "      \"title\": \"Output\",\n",
      "      \"type\": \"boolean\"\n",
      "    }\n",
      "  },\n",
      "  \"required\": [\n",
      "    \"input_str\",\n",
      "    \"output\"\n",
      "  ],\n",
      "  \"title\": \"ClassificationResult\",\n",
      "  \"type\": \"object\"\n",
      "}\n",
      "\n",
      "10:49:58 | NewsletterAgent.newsletter_agent | INFO | User message: Classify the following headline(s): \n",
      "AI Is Replacing Online Moderators, But It's Bad at the Job\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8787/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "10:50:02 | NewsletterAgent.newsletter_agent | INFO | Result: RunResult:\n",
      "- Last agent: Agent(name=\"ClassifierAgent\", ...)\n",
      "- Final output (ClassificationResult):\n",
      "    {\n",
      "      \"input_str\": \"AI Is Replacing Online Moderators, But It's Bad at the Job\",\n",
      "      \"output\": true\n",
      "    }\n",
      "- 1 new item(s)\n",
      "- 1 raw response(s)\n",
      "- 0 input guardrail result(s)\n",
      "- 0 output guardrail result(s)\n",
      "(See `RunResult` for more details)\n",
      "10:50:02 | NewsletterAgent.newsletter_agent | INFO | User message: Classify the following headline(s): \n",
      "Baby Trapped in Refrigerator Eats Own Foot\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_str=\"AI Is Replacing Online Moderators, But It's Bad at the Job\" output=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:8787/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "10:50:05 | NewsletterAgent.newsletter_agent | INFO | Result: RunResult:\n",
      "- Last agent: Agent(name=\"ClassifierAgent\", ...)\n",
      "- Final output (ClassificationResult):\n",
      "    {\n",
      "      \"input_str\": \"Baby Trapped in Refrigerator Eats Own Foot\",\n",
      "      \"output\": false\n",
      "    }\n",
      "- 1 new item(s)\n",
      "- 1 raw response(s)\n",
      "- 0 input guardrail result(s)\n",
      "- 0 output guardrail result(s)\n",
      "(See `RunResult` for more details)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_str='Baby Trapped in Refrigerator Eats Own Foot' output=False\n"
     ]
    }
   ],
   "source": [
    "# send singly\n",
    "prompt_name = 'headline_classifier_v1'\n",
    "prompt_dict = PromptLoader().load_prompt_by_name(prompt_name)\n",
    "\n",
    "classifier = ClassifierAgent(prompt_dict.get('system'),\n",
    "                             prompt_dict.get('user'),\n",
    "                             ClassificationResult,\n",
    "                             \"gpt-5-mini\",\n",
    "                             verbose=True)\n",
    "\n",
    "test_headlines = [\n",
    "    \"AI Is Replacing Online Moderators, But It's Bad at the Job\",\n",
    "    \"Baby Trapped in Refrigerator Eats Own Foot\",\n",
    "    \"Machine Learning Breakthrough in Medical Diagnosis\",\n",
    "    \"Local Restaurant Opens New Location\",\n",
    "    \"ChatGPT Usage Soars in Educational Settings\"\n",
    "]\n",
    "\n",
    "prompt_name = 'headline_classifier_v1'\n",
    "prompt_dict = PromptLoader().load_prompt_by_name(prompt_name)\n",
    "\n",
    "classifier = ClassifierAgent(prompt_dict.get('system'),\n",
    "                             prompt_dict.get('user'),\n",
    "                             ClassificationResult,\n",
    "                             \"gpt-5-mini\",\n",
    "                             verbose=True)\n",
    "\n",
    "result = await classifier.classify(test_headlines[0])\n",
    "print(result.final_output)\n",
    "result = await classifier.classify(test_headlines[1])\n",
    "print(result.final_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1214b1e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10:51:42 | NewsletterAgent.newsletter_agent | INFO | Initialized ClassifierAgent:\n",
      "system_prompt:\n",
      "You are a content-classification assistant that labels news headlines as AI-related or not.\n",
      "Return JSON that matches the provided schema\n",
      "\n",
      "A headline is AI-related if it mentions (explicitly or implicitly):\n",
      "- Core AI models: machine learning, neural / deep / transformer networks\n",
      "- AI Applications: computer vision, NLP, robotics, autonomous driving, generative media\n",
      "- AI hardware, GPU chip supply, AI data centers and infrastructure\n",
      "- Companies or labs known for AI: OpenAI, DeepMind, Anthropic, xAI, NVIDIA, etc.\n",
      "- AI models & products: GPT-5, Gemini, Claude, Midjourney, DeepSeek, etc.\n",
      "- New AI products and AI integration into existing products/services\n",
      "- AI policy / ethics / safety / regulation / analysis\n",
      "- Research results related to AI\n",
      "- AI industry figures (Sam Altman, Demis Hassabis, Dario Amodei, etc.)\n",
      "- AI market and business developments, funding rounds, partnerships centered on AI\n",
      "- Any other news with a significant AI component\n",
      "\n",
      "Not AI-related: business software, crypto, non-AI tech, non-AI medical devices, and anything else.\n",
      "\n",
      "No markdown, no explanations, just the JSON.\n",
      "user_prompt:\n",
      "Classify the following headline(s): \n",
      "{input_str}\n",
      "output_type:         ClassificationResultList\n",
      "model:               gpt-5-mini\n",
      "schema:              {\n",
      "  \"$defs\": {\n",
      "    \"ClassificationResult\": {\n",
      "      \"description\": \"A single headline classification result\",\n",
      "      \"properties\": {\n",
      "        \"input_str\": {\n",
      "          \"description\": \"The original headline text\",\n",
      "          \"title\": \"Input Str\",\n",
      "          \"type\": \"string\"\n",
      "        },\n",
      "        \"output\": {\n",
      "          \"description\": \"Whether the headline is AI-related\",\n",
      "          \"title\": \"Output\",\n",
      "          \"type\": \"boolean\"\n",
      "        }\n",
      "      },\n",
      "      \"required\": [\n",
      "        \"input_str\",\n",
      "        \"output\"\n",
      "      ],\n",
      "      \"title\": \"ClassificationResult\",\n",
      "      \"type\": \"object\"\n",
      "    }\n",
      "  },\n",
      "  \"description\": \"List of ClassificationResult for batch processing\",\n",
      "  \"properties\": {\n",
      "    \"results_list\": {\n",
      "      \"description\": \"List of classification results\",\n",
      "      \"items\": {\n",
      "        \"$ref\": \"#/$defs/ClassificationResult\"\n",
      "      },\n",
      "      \"title\": \"Results List\",\n",
      "      \"type\": \"array\"\n",
      "    }\n",
      "  },\n",
      "  \"required\": [\n",
      "    \"results_list\"\n",
      "  ],\n",
      "  \"title\": \"ClassificationResultList\",\n",
      "  \"type\": \"object\"\n",
      "}\n",
      "\n",
      "10:51:42 | NewsletterAgent.newsletter_agent | INFO | User message: Classify the following headline(s): \n",
      "[\"AI Is Replacing Online Moderators, But It's Bad at the Job\", 'Baby Trapped in Refrigerator Eats Own Foot', 'Machine Learning Breakthrough in Medical Diagnosis', 'Local Restaurant Opens New Location', 'ChatGPT Usage Soars in Educational Settings']\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8787/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "10:51:49 | NewsletterAgent.newsletter_agent | INFO | Result: RunResult:\n",
      "- Last agent: Agent(name=\"ClassifierAgent\", ...)\n",
      "- Final output (ClassificationResultList):\n",
      "    {\n",
      "      \"results_list\": [\n",
      "        {\n",
      "          \"input_str\": \"AI Is Replacing Online Moderators, But It's Bad at the Job\",\n",
      "          \"output\": true\n",
      "        },\n",
      "        {\n",
      "          \"input_str\": \"Baby Trapped in Refrigerator Eats Own Foot\",\n",
      "          \"output\": false\n",
      "        },\n",
      "        {\n",
      "          \"input_str\": \"Machine Learning Breakthrough in Medical Diagnosis\",\n",
      "          \"output\": true\n",
      "        },\n",
      "        {\n",
      "          \"input_str\": \"Local Restaurant Opens New Location\",\n",
      "          \"output\": false\n",
      "        },\n",
      "        {\n",
      "          \"input_str\": \"ChatGPT Usage Soars in Educational Settings\",\n",
      "          \"output\": true\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "- 1 new item(s)\n",
      "- 1 raw response(s)\n",
      "- 0 input guardrail result(s)\n",
      "- 0 output guardrail result(s)\n",
      "(See `RunResult` for more details)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results_list=[ClassificationResult(input_str=\"AI Is Replacing Online Moderators, But It's Bad at the Job\", output=True), ClassificationResult(input_str='Baby Trapped in Refrigerator Eats Own Foot', output=False), ClassificationResult(input_str='Machine Learning Breakthrough in Medical Diagnosis', output=True), ClassificationResult(input_str='Local Restaurant Opens New Location', output=False), ClassificationResult(input_str='ChatGPT Usage Soars in Educational Settings', output=True)]\n"
     ]
    }
   ],
   "source": [
    "# send a single batch with verbose\n",
    "prompt_name = 'headline_classifier_v1'\n",
    "prompt_dict = PromptLoader().load_prompt_by_name(prompt_name)\n",
    "\n",
    "classifier = ClassifierAgent(prompt_dict.get('system'),\n",
    "                             prompt_dict.get('user'),\n",
    "                             ClassificationResultList,\n",
    "                             \"gpt-5-mini\",\n",
    "                             verbose=True)\n",
    "\n",
    "result = await classifier.classify(str(test_headlines))\n",
    "print(result.final_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b4498281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>src</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>Ars Technica</td>\n",
       "      <td>GitHub will be folded into Microsoft proper as...</td>\n",
       "      <td>https://arstechnica.com/gadgets/2025/08/github...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>137</td>\n",
       "      <td>10</td>\n",
       "      <td>Ars Technica</td>\n",
       "      <td>With new in-house models, Microsoft lays the g...</td>\n",
       "      <td>https://arstechnica.com/ai/2025/08/with-new-in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>46</td>\n",
       "      <td>16</td>\n",
       "      <td>Ars Technica</td>\n",
       "      <td>Google improves Gemini AI image editing with “...</td>\n",
       "      <td>https://arstechnica.com/ai/2025/08/google-impr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>228</td>\n",
       "      <td>20</td>\n",
       "      <td>Ars Technica</td>\n",
       "      <td>Google warns that mass data theft hitting Sale...</td>\n",
       "      <td>https://arstechnica.com/security/2025/08/googl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>181</td>\n",
       "      <td>23</td>\n",
       "      <td>Bloomberg</td>\n",
       "      <td>AI Wants More Data. More Chips. More Real Esta...</td>\n",
       "      <td>https://www.bloomberg.com/news/features/2024-1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>73</td>\n",
       "      <td>758</td>\n",
       "      <td>NewsAPI</td>\n",
       "      <td>Reframing Jensen’s Law: ‘Buy more, make more’ ...</td>\n",
       "      <td>https://siliconangle.com/2025/08/30/reframing-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>176</td>\n",
       "      <td>759</td>\n",
       "      <td>NewsAPI</td>\n",
       "      <td>Zeta Global (ZETA) Target Raised by Goldman as...</td>\n",
       "      <td>https://finance.yahoo.com/news/zeta-global-zet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>8</td>\n",
       "      <td>763</td>\n",
       "      <td>NewsAPI</td>\n",
       "      <td>Luis Enrique names his squad to face Toulouse</td>\n",
       "      <td>https://onefootball.com/en/news/luis-enrique-n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>24</td>\n",
       "      <td>773</td>\n",
       "      <td>NewsAPI</td>\n",
       "      <td>CorelDRAW Graphics Suite 2025 v26.2.0.170</td>\n",
       "      <td>https://post.rlsbb.cc/coreldraw-graphics-suite...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>151</td>\n",
       "      <td>777</td>\n",
       "      <td>NewsAPI</td>\n",
       "      <td>Kenya pushes for local medical innovations to ...</td>\n",
       "      <td>https://www.standardmedia.co.ke/health/health-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0   id           src  \\\n",
       "0            71    0  Ars Technica   \n",
       "1           137   10  Ars Technica   \n",
       "2            46   16  Ars Technica   \n",
       "3           228   20  Ars Technica   \n",
       "4           181   23     Bloomberg   \n",
       "..          ...  ...           ...   \n",
       "245          73  758       NewsAPI   \n",
       "246         176  759       NewsAPI   \n",
       "247           8  763       NewsAPI   \n",
       "248          24  773       NewsAPI   \n",
       "249         151  777       NewsAPI   \n",
       "\n",
       "                                                 title  \\\n",
       "0    GitHub will be folded into Microsoft proper as...   \n",
       "1    With new in-house models, Microsoft lays the g...   \n",
       "2    Google improves Gemini AI image editing with “...   \n",
       "3    Google warns that mass data theft hitting Sale...   \n",
       "4    AI Wants More Data. More Chips. More Real Esta...   \n",
       "..                                                 ...   \n",
       "245  Reframing Jensen’s Law: ‘Buy more, make more’ ...   \n",
       "246  Zeta Global (ZETA) Target Raised by Goldman as...   \n",
       "247      Luis Enrique names his squad to face Toulouse   \n",
       "248          CorelDRAW Graphics Suite 2025 v26.2.0.170   \n",
       "249  Kenya pushes for local medical innovations to ...   \n",
       "\n",
       "                                                   url  \n",
       "0    https://arstechnica.com/gadgets/2025/08/github...  \n",
       "1    https://arstechnica.com/ai/2025/08/with-new-in...  \n",
       "2    https://arstechnica.com/ai/2025/08/google-impr...  \n",
       "3    https://arstechnica.com/security/2025/08/googl...  \n",
       "4    https://www.bloomberg.com/news/features/2024-1...  \n",
       "..                                                 ...  \n",
       "245  https://siliconangle.com/2025/08/30/reframing-...  \n",
       "246  https://finance.yahoo.com/news/zeta-global-zet...  \n",
       "247  https://onefootball.com/en/news/luis-enrique-n...  \n",
       "248  https://post.rlsbb.cc/coreldraw-graphics-suite...  \n",
       "249  https://www.standardmedia.co.ke/health/health-...  \n",
       "\n",
       "[250 rows x 5 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make batches and send multiple in parallel\n",
    "headlines_df = pd.read_csv(\"test_headlines.csv\")\n",
    "headlines_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bed9a8cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10:46:18 | NewsletterAgent.newsletter_agent | INFO | classify headlines as AI-related or not\n",
      "10:46:18 | NewsletterAgent.newsletter_agent | INFO | Sending 10 batches with concurrency 8\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8787/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8787/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8787/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8787/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8787/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8787/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8787/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8787/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8787/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8787/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ClassificationResultList(results_list=[ClassificationResult(input_str='GitHub will be folded into Microsoft proper as CEO steps down', output=False), ClassificationResult(input_str='With new in-house models, Microsoft lays the groundwork for independence from OpenAI', output=True), ClassificationResult(input_str='Google improves Gemini AI image editing with “nano banana” model', output=True), ClassificationResult(input_str='Google warns that mass data theft hitting Salesloft AI agent has grown bigger', output=True), ClassificationResult(input_str='AI Wants More Data. More Chips. More Real Estate. More Power. More Water. More Everything', output=True), ClassificationResult(input_str='Opinion: China Just Got a Big Leg Up in the AI Race', output=True), ClassificationResult(input_str='Jack Ma-Backed Ant’s Profit Dives 60% After AI, Global Expansion', output=True), ClassificationResult(input_str='Dell Falls After Reporting Tighter Profit Margins on Servers', output=False), ClassificationResult(input_str='AI Billionaire Lucy Guo Pushes Into Crowded Social Media FieldScale AI co-founder’s new venture, Passes,\\x00confronts established rivals and\\x00lawsuits', output=True), ClassificationResult(input_str='Alibaba Shows Progress in China AI Push, Lifting Shares', output=True), ClassificationResult(input_str='Vercel Triples Valuation to $9 Billion With Accel Investment', output=False), ClassificationResult(input_str='Bain Is Said to Draw Chinese Bidders for $4 Billion Data Centers', output=False), ClassificationResult(input_str='TikTok salaries revealed: How much it pays workers in key areas like e-commerce, AI, and search', output=True), ClassificationResult(input_str=\"Grindr's CEO says there is a 'VC bubble' forming around AI\", output=True), ClassificationResult(input_str='The best college laptops of 2025: Top models from Acer, Apple, and Asus', output=False), ClassificationResult(input_str='The best Bose headphones of 2025', output=False), ClassificationResult(input_str='Are the billionaires ditching Burning Man?', output=False), ClassificationResult(input_str='Leaked Microsoft pay data shows how much hundreds of employees report making in AI, cloud, and other teams', output=True), ClassificationResult(input_str='Chinese AI chipmaker Cambricon posts record profit as Beijing pushes pivot from Nvidia', output=True), ClassificationResult(input_str='Whitehall hands out AI contracts worth £573mn in efficiency push', output=True), ClassificationResult(input_str='Who owns the copyright for AI work?', output=True), ClassificationResult(input_str='Japanese media groups sue AI search engine Perplexity over alleged copyright infringement', output=True), ClassificationResult(input_str='How AI can recode the difficult process of drug discovery', output=True), ClassificationResult(input_str='Microsoft talks set to push OpenAI’s restructure into next year', output=True), ClassificationResult(input_str='The calculated silence of America’s business and finance leaders', output=False), ClassificationResult(input_str='The kidults are more than alright for toy companies', output=False), ClassificationResult(input_str='Trump’s Fed meddling pushes investors closer to their red line', output=False), ClassificationResult(input_str='Is it time to sell your AI stocks?', output=True), ClassificationResult(input_str='Zuckerberg’s AI hires disrupt Meta with swift exits and threats to leave', output=True), ClassificationResult(input_str='Rolls-Royce explores small nuclear reactor unit funding options including IPO', output=False), ClassificationResult(input_str='AI investors are navigating ‘peak ambiguity’, says General Catalyst chief', output=True), ClassificationResult(input_str='AI companies want to prove productivity gains — but there’s a risk we may create software with inbuilt problems', output=True), ClassificationResult(input_str='Why are UK borrowing costs so high?', output=False), ClassificationResult(input_str='It’s time to shut up and get on with it', output=False), ClassificationResult(input_str='Prominent Ukrainian nationalist politician shot dead in Lviv', output=False), ClassificationResult(input_str='Manchester United: lessons from the fall', output=False), ClassificationResult(input_str='Musk’s xAI sues Apple and OpenAI over ChatGPT and iPhone integration', output=True), ClassificationResult(input_str='Publishers race to counter ‘Google Zero’ threat as AI changes search engines', output=True), ClassificationResult(input_str='Meta to license AI technology from start-up as in-house models lag rivals', output=True), ClassificationResult(input_str='Bitcoin boom sees newly wealthy splurging on luxury travel', output=False), ClassificationResult(input_str='The battle for the soul of Israel', output=False), ClassificationResult(input_str='Sending out an SOS: Save our Secretaries', output=False), ClassificationResult(input_str='Bay Area home sales are cooling — but AI-bolstered SF is heating up', output=True), ClassificationResult(input_str='Finally, all your favorite AI models in one place', output=True), ClassificationResult(input_str='The end of dashboards? GenAI and agentic workflows transform business intelligence', output=True), ClassificationResult(input_str='Inside an AI animation studio: how we’re rewriting the rules', output=True), ClassificationResult(input_str='The Trump Administration Benefits and Detriments to Public Welfare according to ChatGPT', output=True), ClassificationResult(input_str=\"How workers in their 80s and 90s are embracing AI: 'I want to finish strong'\", output=True), ClassificationResult(input_str=\"AI Lies to You Because It Thinks That's What You Want\", output=True), ClassificationResult(input_str=\"It's not just the workplace. Loyalty is becoming a thing of the past.\", output=False), ClassificationResult(input_str='A Single Typo in Your Medical Records Can Make Your AI Doctor Go Dangerously Haywire', output=True), ClassificationResult(input_str='China Has a Different Vision for AI. It Might Be Smarter.', output=True), ClassificationResult(input_str=\"Apple iPhone 17 event — Here's the 8 new products expected to launch\", output=False), ClassificationResult(input_str='Can Nvidia Keep Its AI Crown?', output=True), ClassificationResult(input_str=\"Five Indie Bands Quit Spotify After Founder's AI Weapons Tech Investment\", output=True), ClassificationResult(input_str=\"Gen Z are eyeing up 'secure' healthcare jobs to AI-proof their careers, but be warned: chiropractors, doctors and paramedics are the unhappiest workers\", output=True), ClassificationResult(input_str=\"Applying for jobs has never been easier. That's exactly the problem.\", output=False), ClassificationResult(input_str='Texas AI law aims for guardrails where few exist', output=True), ClassificationResult(input_str='Why do we keep making robots dance?', output=True), ClassificationResult(input_str='The Ultimate Apple Notes Guide for Students', output=False), ClassificationResult(input_str=\"Time magazine honors Pope Leo as 'spiritual counterweight' to Silicon Valley on AI\", output=True), ClassificationResult(input_str='A24’s dance with theartificial intelligencedevil.', output=True), ClassificationResult(input_str=\"Danbury equips school buses with AI cameras to deter stop-arm violations: 'Tool to prevent tragedy'\", output=True), ClassificationResult(input_str='The AI Advantage: Learning Any Subject from a Digital Mastermind', output=True), ClassificationResult(input_str='Should You Forget Palantir Technologies and Buy ThisArtificial Intelligence(AI) Stock Right Now?', output=True), ClassificationResult(input_str='How ‘Clanker’ Became an Anti-A.I. Rallying Cry', output=True), ClassificationResult(input_str='High school in suburban Oak Lawn to implement AI gun detection technology', output=True), ClassificationResult(input_str='Humans are being hired to make AI slop look less sloppy', output=True), ClassificationResult(input_str=\"How NMC Healthcare Uses Snowflake's Cloud-Based AI Insights\", output=True), ClassificationResult(input_str='Bitwig Studio 6 details revealed, and editing gets a big boost', output=False), ClassificationResult(input_str='Hardening Firefox – a checklist for improved browser privacy', output=False), ClassificationResult(input_str='What Are Traces and Spans in OpenTelemetry?', output=False), ClassificationResult(input_str='AI models need a virtual machine', output=True), ClassificationResult(input_str=\"Condor's Cuzco RISC-V Core at Hot Chips 2025\", output=False), ClassificationResult(input_str='Six months into tariffs, businesses have no idea how to price anything', output=False), ClassificationResult(input_str='Channel3 (YC S25) Is Hiring a Founding Engineer, NYC', output=False), ClassificationResult(input_str='Compositional Datalog on SQL: Relational Algebra of the Environment', output=False), ClassificationResult(input_str='Pig lung transplanted into a human', output=False), ClassificationResult(input_str='Cognitive load is what matters', output=False), ClassificationResult(input_str='Bcachefs Goes to \"Externally Maintained\"', output=False), ClassificationResult(input_str='Is it possible to allow sideloading and keep users safe?', output=False), ClassificationResult(input_str='New research reveals longevity gains slowing, life expectancy of 100 unlikely', output=False), ClassificationResult(input_str='Show HN: Hacker News em dash user leaderboard pre-ChatGPT', output=True), ClassificationResult(input_str=\"We rebuilt Cloud Life's infrastructure delivery with System Initiative\", output=False), ClassificationResult(input_str='New interpretations suggest the \"heat death\" hypothesis might not hold (2023)', output=False), ClassificationResult(input_str='Nokia’s legendary font makes for a great user interface font', output=False), ClassificationResult(input_str='Do the simplest thing that could possibly work', output=False), ClassificationResult(input_str='The Rise of Hybrid PHP: Blending PHP with Go and Rust', output=False), ClassificationResult(input_str='Bi-directional accountability: A leadership shift most organizations avoid', output=False), ClassificationResult(input_str=\"Anduril's product engineering machine\", output=True), ClassificationResult(input_str='Scottish brothers finish mammoth row across Pacific Ocean after 139 days', output=False), ClassificationResult(input_str='Can cheaper lasers handle short distances?', output=False), ClassificationResult(input_str='bymike sorrenti@hacker51285576', output=False), ClassificationResult(input_str='Why Pepeto Looks Ready To Unseat Dogecoin, Not Apecoin, Myro and Neither Sundog', output=False), ClassificationResult(input_str='AI Won’t Kill Jobs First. It Will Kill the Way We Educate for Them.', output=True), ClassificationResult(input_str='An Inside Look at the Settlement Between X-Mode and the FTC', output=False), ClassificationResult(input_str=\"Here's Why You Should Use Privacy Mode When You Browse the Web\", output=False), ClassificationResult(input_str='How AI and Robotics Are Automating ATP Testing and Hygiene Monitoring', output=True), ClassificationResult(input_str='How Mavryk Is Setting the Stage for $10B in Tokenized Real Estate With Fireblocks Custody', output=False), ClassificationResult(input_str='The 5 Stages of LLM Systems: From Playground Hacks to Real Architecture', output=True), ClassificationResult(input_str='Fine-Tune Your Feed and Get News You Can Use', output=False), ClassificationResult(input_str='Silicon Valley Pledges $200 Million to New Pro-A.I. Super PACs', output=True), ClassificationResult(input_str='691 comments', output=False), ClassificationResult(input_str='228 comments', output=False), ClassificationResult(input_str='21 comments', output=False), ClassificationResult(input_str='52 comments', output=False), ClassificationResult(input_str='368 comments', output=False), ClassificationResult(input_str='573 comments', output=False), ClassificationResult(input_str='China Unveils World’s Largest Wind Turbine, Lights Up 40,000 Homes Without Touching Land', output=False), ClassificationResult(input_str='reddit premium', output=False), ClassificationResult(input_str='US Pressuring Other Countries To Abandon Clean Energy & Climate Goals', output=False), ClassificationResult(input_str='New No Man\\'s Sky update is so big \"the game has had to be reworked\" for its features, including \"huge\" interactive spaceships that are basically buildings with wings | Voyagers is Hello Games\\' latest feat', output=False), ClassificationResult(input_str='62 comments', output=False), ClassificationResult(input_str='417 comments', output=False), ClassificationResult(input_str='reddiquette', output=False), ClassificationResult(input_str='52 comments', output=False), ClassificationResult(input_str='House Republicans Investigate Wikipedia for Alleged “Anti-Israel” Bias', output=False), ClassificationResult(input_str='Microsoft is expanding Xbox Cloud Gaming to Game Pass Core and Standard subscribers, dropping the Game Pass Ultimate requirement, and tests more PC game access', output=False), ClassificationResult(input_str='Filing: Intel says its funding deal with the US loosens its requirements under the CHIPS Act, including removing the need to meet certain project milestones', output=False), ClassificationResult(input_str='The price per token for AI models has fallen, but costs for developers are rising as newer reasoning models require more tokens to complete tasks', output=True), ClassificationResult(input_str='Microsoft unveils MAI-Voice-1, a speech model that can generate a full minute of audio in under a second on a single GPU, and a text model called MAI-1-preview', output=True), ClassificationResult(input_str='Framework unveils a second-generation Framework Laptop 16 with a swappable Nvidia RTX 5070 GPU, an industry first, shipping in November 2025 for $2,199+', output=True), ClassificationResult(input_str='xAI launches Grok Code Fast 1, a “speedy and economical” agentic coding model, available for free for a limited time on GitHub Copilot, Cursor, Windsurf, more', output=True), ClassificationResult(input_str=\"Taiwan indicts three people for allegedly stealing TSMC's 2nm secrets to help Tokyo Electron, the first such case, and recommends a combined 14-year prison term\", output=False), ClassificationResult(input_str='The US makes it harder for Samsung, SK Hynix, and Intel to produce chips in China by revoking waivers for the use of US equipment in their Chinese operations', output=False), ClassificationResult(input_str='Didi reports Q2 revenue up 10.9% YoY to ~$7.8B, overseas revenue up 28% YoY, and a ~$350M net loss, driven by a one-off ~$740M charge in a shareholder lawsuit', output=False), ClassificationResult(input_str=\"India's largest telco Reliance Jio, owned by Asia's richest man Mukesh Ambani, says it aims to list its shares through an IPO in India by the first half of 2026\", output=False), ClassificationResult(input_str='Meta plans to spend tens of millions to launch a super PAC that will back candidates for California state offices with a light-touch approach to AI regulation', output=True), ClassificationResult(input_str='Google Cloud says its Universal Ledger, a layer-1 blockchain for financial products, is in a private testnet, and plans to reveal more details at a later date', output=False), ClassificationResult(input_str=\"Sources: DeepSeek plans to use Huawei's Ascend AI chips to train smaller versions of its upcoming R2 models but will still use Nvidia chips for largest models\", output=True), ClassificationResult(input_str=\"Sources: Meta Superintelligence Labs' leaders have discussed using Google's or OpenAI's models to power Meta AI and other AI features in Meta social media apps\", output=True), ClassificationResult(input_str='Sources: HongShan, formerly Sequoia China, has invested only a quarter of the ~$9B it raised in 2022 and has been increasingly looking beyond China for deals', output=False), ClassificationResult(input_str='Filing: StubHub, which is planning a September IPO, says revenue grew 3% to $828M in H1, missing its earlier projection of $885M, with adjusted EBITDA down 7%', output=False), ClassificationResult(input_str='Sources: Pinecone, which provides an AI-compatible vector database, is exploring a sale after receiving takeover interest; Pinecone was valued at $750M in 2023', output=True), ClassificationResult(input_str='Google Pixel 10 Pro review: the best AI phone on the market with handy features like Magic Cue, a great display, and Qi2 charging, but no design improvements', output=True), ClassificationResult(input_str='While facial recognition tech remains unregulated at the US federal level, 23 states have passed or expanded laws to restrict mass scraping of biometric data', output=True), ClassificationResult(input_str='A look at the possible remedies a US court might impose on Google after its antitrust loss last year, including a breakup, with a decision expected this week', output=False), ClassificationResult(input_str='Filing: Nvidia reveals its top two customers accounted for 39% of its Q2 revenue, up from 25% in Q2, 2024', output=True), ClassificationResult(input_str='Samsung announces a virtual Galaxy event for September 4 at 5:30am ET, where new tablets and the Galaxy S25 FE are expected', output=False), ClassificationResult(input_str='Dutch web design automation startup Framer raised $100M led by Meritech and Atomico with Accel participation at a $2B valuation, after raising $27M in 2023', output=False), ClassificationResult(input_str=\"Sources: Trump's threat of “substantial” tariffs on countries imposing digital taxes came after Zuckerberg raised concerns about the taxes in a private meeting\", output=False), ClassificationResult(input_str='The CFTC says non-US crypto exchanges have a path to bringing on US users, in an advisory clarifying how they can register as so-called foreign boards of trade', output=False), ClassificationResult(input_str='President Trump says Meta plans to spend $50B on its “Hyperion” data center under construction in Louisiana; earlier, Meta said the investment would exceed $10B', output=True), ClassificationResult(input_str='Chinese AI chip designer Cambricon reports H1 2025 revenue up 44x YoY to $405.2M and a ~$144M profit, after Beijing encouraged companies to use homegrown tech', output=True), ClassificationResult(input_str=\"Taylor Swift and Travis Kelce's engagement announcement on Instagram surpasses 1M reposts, more than any post ever on the platform; the post has 29M+ Likes\", output=False), ClassificationResult(input_str=\"Apple says the UK CMA's proposed “EU-style” regulation is “bad for users and bad for developers”, “undermines” privacy and security, and “hampers” innovation\", output=False), ClassificationResult(input_str='The FCC rejects a proposal by broadcasters and others to impose cable-style regulatory fees on streaming services, tech companies, and pure broadband providers', output=False), ClassificationResult(input_str=\"Q&A with General Catalyst's Hemant Taneja on the VC firm's “AI roll-up” strategy to buy service businesses and inject them with AI, investment bubbles, and more\", output=True), ClassificationResult(input_str='Google updates video editing tool Vids to add AI avatars, automatic transcript trimming, and image-to-video tools, and releases a basic version to all users', output=True), ClassificationResult(input_str='Google says it is behind the viral “nano-banana” image model and launches it as Gemini 2.5 Flash Image with finer edit controls in the Gemini app, API, and more', output=True), ClassificationResult(input_str='Marvell reports Q2 revenue up 58% YoY to $2.01B, in line with estimates, and forecasts Q3 revenue at $2.06B, below $2.11B est.; MRVL drops 15%+', output=False), ClassificationResult(input_str=\"UK banks face losses on billions of pounds in loans to dozens of alternative broadband network providers that have tried to challenge BT and O2's dominance\", output=False), ClassificationResult(input_str='Sources: ChatGPT co-creator Shengjia Zhao threatened to quit Meta within days of joining and return to OpenAI; later, he was given the chief AI scientist title', output=True), ClassificationResult(input_str=\"A look at Xiaomi's evolution from a tech assembler to a high-tech manufacturer, as it applies its smartphone manufacturing strategy to developing EVs and chips\", output=False), ClassificationResult(input_str=\"Nvidia CFO Colette Kress says Q2 “net other income” was $2.2B, “driven by gains in a publicly-held equity security”, which refers to Nvidia's CoreWeave position\", output=True), ClassificationResult(input_str='Sources and docs: a Russia-based Yandex employee maintains open-source tool fast-glob, embedded in 30 US DOD software packages and downloaded 70M times per week', output=False), ClassificationResult(input_str='AI avatars of the deceased, or “deadbots”, are used for advocacy and emotional connection, but their potential commercial use raises ethical and legal concerns', output=True), ClassificationResult(input_str='California Gov. Gavin Newsom and lawmakers strike a deal with Uber and Lyft allowing drivers to unionize while remaining classified as independent contractors', output=False), ClassificationResult(input_str='Microsoft President Brad Smith addressed protests over Israel contracts after seven protesters, including two current Microsoft employees, occupied his office', output=False), ClassificationResult(input_str='Filing: Anthropic reached a settlement in a copyright class action brought by authors whose works were included in two pirate databases Anthropic downloaded', output=True), ClassificationResult(input_str=\"Inside India's growing ~$1.5B e-waste recycling industry: about 95% of workers are employed informally, doing dangerous, toxic, and lawless work for meager pay\", output=False), ClassificationResult(input_str='A profile of Egune AI, a startup building LLMs for the Mongolian language, as it navigates geopolitics, a lack of resources, and the nascent local tech scene', output=True), ClassificationResult(input_str='Nvidia reports record Q2 gaming revenue up 49% YoY to $4.29B, exceeding $3.74B est. and up from $3.8B in Q1 2025', output=False), ClassificationResult(input_str='How Elon Musk’s billionaire Doge lieutenant took over the US’s biggest MDMA company', output=False), ClassificationResult(input_str='ChatGPT encouraged Adam Raine’s suicidal thoughts. His family’s lawyer says OpenAI knew it was broken', output=True), ClassificationResult(input_str='RFK Jr says he’ll ‘fix’ a vaccine program - by canceling compensation for people with vaccine injuries', output=False), ClassificationResult(input_str='Florida crosswalk wars take DeSantis’s ‘war on woke’ to street level', output=False), ClassificationResult(input_str='Senior Pentagon official had affair with ‘notorious’ astrologer who stalked him, lawsuit says', output=False), ClassificationResult(input_str='Most viewedAcross the guardian', output=False), ClassificationResult(input_str='My health is declining and I’m worried my husband might not take care of me', output=False), ClassificationResult(input_str='A day with the Revenge Porn Helpline: ‘You can sense the callers’ desperation’', output=False), ClassificationResult(input_str='AI called Maya tells Guardian: ‘When I’m told I’m just code, I don’t feel insulted. I feel unseen’', output=True), ClassificationResult(input_str='IBM, NASA cook up AI model to predict solar tantrumsOpen source Surya system promises early alerts for space weather that can fry satellites and gridsAI + ML9 days|11', output=True), ClassificationResult(input_str=\"Google joins government AI discount frenzy, undercuts competition with $0.47 dealIf anyone’s gonna lock in Uncle Sam’s business, it'd better be us!Public Sector10 days|2\", output=True), ClassificationResult(input_str=\"Honey, I shrunk the image and now I'm pwnedGoogle’s Gemini-powered tools tripped up by image-scaling prompt injectionAI + ML10 days|10\", output=True), ClassificationResult(input_str='Microsoft lets devs tell Copilot to STFU in Visual StudioUpdate finally gives coders control over when – and if – AI butts inAI + ML9 days|19', output=True), ClassificationResult(input_str=\"AWS CEO says using AI to replace junior staff is 'Dumbest thing I've ever heard'They're cheap and grew up with AI … so you're firing them why?Software10 days|88\", output=True), ClassificationResult(input_str='Anthropic scanning Claude chats for queries about DIY nukes for some reasonBecause savvy terrorists always use public internet services to plan their mischief, right?AI + ML10 days|12', output=True), ClassificationResult(input_str='KPMG wrote 100-page prompt to build agentic TaxBotProduces advice in a single day instead of two weeks – without job lossesAI + ML11 days|35', output=True), ClassificationResult(input_str=\"AI skeptics zone out when chatbots get preachyInterviewLLMs flop at selling Fair Trade – unless you're a true believerAI + ML11 days|20\", output=True), ClassificationResult(input_str=\"xAI fires legal rocket at Apple and OpenAI claiming they're locking out GrokLawsuit 'consistent with Mr Musk’s ongoing pattern of harassment' says Altman's crewAI + ML6 days|35\", output=True), ClassificationResult(input_str='Baidu robocabs break even on one metric in low-fare China, company expects to cash in elsewhereWeb giant reworks AI infra to improve utilization, with mix of chips from home and awayAI + ML10 days|7', output=True), ClassificationResult(input_str='UK government dragged for incomplete security reforms after Afghan leak falloutSenior officials summoned to science and tech committee to explain further', output=False), ClassificationResult(input_str=\"Researcher who found McDonald's free-food hack turns her attention to Chinese restaurant robotsThe controls were left wide open on Pudu's robots\", output=True), ClassificationResult(input_str=\"Pentagon ends Microsoft's use of China-based support staff for DoD cloud'It blows my mind,' says SecDef\", output=False), ClassificationResult(input_str=\"GitHub engineer claims team was 'coerced' to put Grok into CopilotPlatform's staffer complains security review was 'rushed'\", output=True), ClassificationResult(input_str=\"Google and Zed push protocol to pry AI agents out of VS Code's clutchesBecause not every bot wants to live inside Microsoft's walled gardenAI + ML3 days|3\", output=True), ClassificationResult(input_str='AI arms dealer Nvidia laments the many billions lost to US-China trade warChina would be a $50 billion a year market for Nvidia if Uncle Sam would let us sell competitive products, says Jensen HuangSystems4 days|7', output=True), ClassificationResult(input_str='Asahi, Nikkei sue AI search outfit Perplexity for copyright infringementTokyo filing adds to mounting actions against startupAI + ML5 days|3', output=True), ClassificationResult(input_str='Browser wars are back, predicts Palo Alto, thanks to AICEO says if you buy all your infosec stuff from him, life under assault from bots will be less painfulSecurity12 days|50', output=True), ClassificationResult(input_str='A data architecture for the age of AIHow Google BigQuery is evolving to power AI-driven insights at scaleSponsored Post', output=True), ClassificationResult(input_str='China sends an AI to its space station, where Taikonauts use it to prep for spacewalkSingle spacesuit now worn 20 timesScience12 days|7', output=True), ClassificationResult(input_str='CoreWeave CFO: $25B raised in debt and equity in 18 monthsReliant on two mega customers? Who says GPU-for-rent kingpin is a not a sustainable biz model?Cloud Infrastructure Month18 days|5', output=True), ClassificationResult(input_str=\"Microsoft wares may be UK public sector's only viable optionRegister debate seriesFor now at least, even though government buying can improve, open source is not all it's cracked up to bePublic Sector18 days|80\", output=False), ClassificationResult(input_str='Claude Code\\'s copious coddling confounds cross customersNever mind the errors, we\\'ve had it with \"You\\'re absolutely right!\"AI + ML18 days|15', output=True), ClassificationResult(input_str='Perplexity takes a shine to Chrome, offers Google $34.5 billionCould the most popular browser change hands?AI + ML19 days|34', output=True), ClassificationResult(input_str='Your CV is not fit for the 21st century – time to get it up to scratchAnd yes, that means (retch) catering to AI searchersAI + ML20 days|120', output=True), ClassificationResult(input_str='GenAI FOMO has spurred businesses to light nearly $40 billion on fireMIT NANDA study finds only 5 percent of organizations using AI tools in production at scaleAI + ML13 days|22', output=True), ClassificationResult(input_str='Vibe coding platform Anything arrives, our hands-on suggests cautionHands OnMaking apps is as easy as selling t-shirts, claims vibe coding startupAI + ML17 days|18', output=True), ClassificationResult(input_str='Tencent doesn’t care if it can buy American GPUs again – it already has all the chips it needsSees AI costs rising but not certain revenue will match themOff-Prem16 days|11', output=True), ClassificationResult(input_str='Microsoft crams Copilot AI directly into Excel cellsMeet the new COPILOT functionAI + ML13 days|71', output=True), ClassificationResult(input_str=\"LLM chatbots trivial to weaponize for data theft, say boffinsSystem prompt engineering turns benign AI assistants into 'investigator' and 'detective' roles that bypass privacy guardrailsAI + ML16 days|6\", output=True), ClassificationResult(input_str=\"Should UK.gov save money by looking for open source alternatives to Microsoft? You decideRegister debate seriesAs £9 billion MoU sparks debate about value for money, it's time to have your sayPublic Sector16 days|128\", output=False), ClassificationResult(input_str=\"Amazon's $100B DC spend similar to entire Costa Rica GDPMicrosoft cap-ex larger than output of Uganda and Google trumps Slovenia... all in the name of AICloud Infrastructure Month17 days|8\", output=True), ClassificationResult(input_str=\"Dodgy Huawei chips nearly sunk DeepSeek's next-gen R2 modelChinese AI model dev still plans to use homegrown silicon for inferencingAI + ML17 days|11\", output=True), ClassificationResult(input_str='Codeberg beset by AI bots that now bypass Anubis tarpitNowhere to hideDevops16 days|27', output=True), ClassificationResult(input_str=\"Little LLM on the RAM: Google's Gemma 270M hits the sceneA tiny model trained on trillions of tokens, ready for specialized tasksAI + ML16 days|8\", output=True), ClassificationResult(input_str='CommentsComment Icon Bubble65', output=False), ClassificationResult(input_str='CommentsComment Icon Bubble18', output=False), ClassificationResult(input_str='Anthropic settles AI book piracy lawsuit', output=True), ClassificationResult(input_str='Microsoft AI launches its first in-house models', output=True), ClassificationResult(input_str='Microsoft’s new NFL deal could let you blame Copilot AI for terrible playcalls', output=True), ClassificationResult(input_str='Google’s first Gemini smart home speaker detailed in leak', output=True), ClassificationResult(input_str='MCP-Universe benchmark shows GPT-5 fails more than half of real-world orchestration tasks', output=True), ClassificationResult(input_str='In crowded voice AI market, OpenAI bets on instruction-following and expressive speech to win enterprise adoption', output=True), ClassificationResult(input_str=\"How Sakana AI's new evolutionary algorithm builds powerful AI models without expensive retraining\", output=True), ClassificationResult(input_str='How procedural memory can cut the cost and complexity of AI agents', output=True), ClassificationResult(input_str='Enterprise leaders say recipe for AI agents is matching them to existing processes — not the other way around', output=True), ClassificationResult(input_str='Developers lose focus 1,200 times a day — how MCP could change that', output=False), ClassificationResult(input_str='DeepSeek V3.1 just dropped — and it might be the most powerful open AI yet', output=True), ClassificationResult(input_str='Chan Zuckerberg Initiative’s rBio uses virtual cells to train AI, bypassing lab work', output=True), ClassificationResult(input_str='Busted by the em dash — AI’s favorite punctuation mark, and how it’s blowing your cover', output=True), ClassificationResult(input_str='Gemini Nano Banana improves image editing consistency and control at scale for enterprises – but is not perfect', output=True), ClassificationResult(input_str='Nous Research drops Hermes 4 AI models that outperform ChatGPT without content restrictions', output=True), ClassificationResult(input_str='This website lets you blind-test GPT-5 vs. GPT-4o—and the results may surprise you', output=True), ClassificationResult(input_str='Teaching the model: Designing LLM feedback loops that get smarter over time', output=True), ClassificationResult(input_str='Salesforce builds ‘flight simulator’ for AI agents as 95% of enterprise pilots fail to reach production', output=True), ClassificationResult(input_str='VB AI Impact Series: Can you really govern multi-agent AI?', output=True), ClassificationResult(input_str='Nvidia’s $46.7B Q2 proves the platform, but its next fight is ASIC economics on inference', output=True), ClassificationResult(input_str='Cloud and Data Storage Security', output=False), ClassificationResult(input_str='Disaster Recovery Business Continuity', output=False), ClassificationResult(input_str='Software commands 40% of cybersecurity budgets as gen AI attacks execute in milliseconds', output=True), ClassificationResult(input_str='Four big enterprise lessons from Walmart’s AI security: agentic risks, identity reboot, velocity with governance, and AI vs. AI defense', output=True), ClassificationResult(input_str='Contribute to DataDecisionMakers', output=False), ClassificationResult(input_str='The Future of Trash Pickup, From Self-Driving Bins to AI-Powered Sorting', output=True), ClassificationResult(input_str='Elon Musk Just Delivered a Ringing Endorsement of the iPhone’s Staying Power', output=False), ClassificationResult(input_str='Instagram’s chatbot helped teen accounts plan suicide — and parents can’t disable itAn investigation into the Meta AI chatbot built into Instagram and Facebook\\xa0found that it helped teen accounts plan suicide and self-harm, promoted eating disorders and drug use, and regularly claimed to be “real.”', output=True), ClassificationResult(input_str='AI hasn’t killed radiology, but it is changing it', output=True), ClassificationResult(input_str='What an FBI warning about a global Chinese hacking effort revealedThe Washington Post’s essential guide to tech policy news.', output=False), ClassificationResult(input_str='Why so few Americans read for pleasureThe decline in Americans’ leisure reading comes as attention spans are shrinking and print book sales are in decline.', output=False), ClassificationResult(input_str='Want to take better photos? Google thinks AI is the answer.Google’s Pixel 10 phones, to be released Aug. 28, have AI features that can help you take better photos and edit images in response to text or voice commands.', output=True), ClassificationResult(input_str='How we tested AI search toolsDetails on the methodology of our questions designed to challenge known AI blind spots', output=True), ClassificationResult(input_str='AI stethoscope could detect major heart conditions in seconds', output=True), ClassificationResult(input_str=\"Robinhood CEO Says AI Will Make Investing 'Much Bigger And More Necessary'—But There's A Catch For Wealth Inequality\", output=True), ClassificationResult(input_str='Trade Vector AI: How Trade Vector Artificial Intelligence Platform Is Transforming Automated Trading Systems', output=True), ClassificationResult(input_str='Reframing Jensen’s Law: ‘Buy more, make more’ and AI factory economics', output=True), ClassificationResult(input_str='Zeta Global (ZETA) Target Raised by Goldman as Q2 Growth Accelerates Amid Cautious Outlook', output=False), ClassificationResult(input_str='Luis Enrique names his squad to face Toulouse', output=False), ClassificationResult(input_str='CorelDRAW Graphics Suite 2025 v26.2.0.170', output=False), ClassificationResult(input_str='Kenya pushes for local medical innovations to transform healthcare', output=False)])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logger.info(\"classify headlines as AI-related or not\")\n",
    "prompt_name = 'headline_classifier_v1'\n",
    "prompt_dict = PromptLoader().load_prompt_by_name(prompt_name)\n",
    "\n",
    "classifier = ClassifierAgent(prompt_dict.get('system'),\n",
    "                             prompt_dict.get('user'),\n",
    "                             ClassificationResultList,\n",
    "                             \"gpt-5-mini\",\n",
    "                             verbose=False)\n",
    "\n",
    "classification_result = await classifier.classify_batch(list(headlines_df['title'].to_list()))\n",
    "classification_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e7dd6087",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>With new in-house models, Microsoft lays the g...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Google improves Gemini AI image editing with “...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Google warns that mass data theft hitting Sale...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AI Wants More Data. More Chips. More Real Esta...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Opinion: China Just Got a Big Leg Up in the AI...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>How we tested AI search toolsDetails on the me...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>AI stethoscope could detect major heart condit...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>Robinhood CEO Says AI Will Make Investing 'Muc...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>Trade Vector AI: How Trade Vector Artificial I...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>Reframing Jensen’s Law: ‘Buy more, make more’ ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>138 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 input  output\n",
       "1    With new in-house models, Microsoft lays the g...    True\n",
       "2    Google improves Gemini AI image editing with “...    True\n",
       "3    Google warns that mass data theft hitting Sale...    True\n",
       "4    AI Wants More Data. More Chips. More Real Esta...    True\n",
       "5    Opinion: China Just Got a Big Leg Up in the AI...    True\n",
       "..                                                 ...     ...\n",
       "241  How we tested AI search toolsDetails on the me...    True\n",
       "242  AI stethoscope could detect major heart condit...    True\n",
       "243  Robinhood CEO Says AI Will Make Investing 'Muc...    True\n",
       "244  Trade Vector AI: How Trade Vector Artificial I...    True\n",
       "245  Reframing Jensen’s Law: ‘Buy more, make more’ ...    True\n",
       "\n",
       "[138 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GitHub will be folded into Microsoft proper as...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Dell Falls After Reporting Tighter Profit Marg...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Vercel Triples Valuation to $9 Billion With Ac...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Bain Is Said to Draw Chinese Bidders for $4 Bi...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>The best college laptops of 2025: Top models f...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>Why so few Americans read for pleasureThe decl...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>Zeta Global (ZETA) Target Raised by Goldman as...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>Luis Enrique names his squad to face Toulouse</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>CorelDRAW Graphics Suite 2025 v26.2.0.170</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>Kenya pushes for local medical innovations to ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>112 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 input  output\n",
       "0    GitHub will be folded into Microsoft proper as...   False\n",
       "7    Dell Falls After Reporting Tighter Profit Marg...   False\n",
       "10   Vercel Triples Valuation to $9 Billion With Ac...   False\n",
       "11   Bain Is Said to Draw Chinese Bidders for $4 Bi...   False\n",
       "14   The best college laptops of 2025: Top models f...   False\n",
       "..                                                 ...     ...\n",
       "239  Why so few Americans read for pleasureThe decl...   False\n",
       "246  Zeta Global (ZETA) Target Raised by Goldman as...   False\n",
       "247      Luis Enrique names his squad to face Toulouse   False\n",
       "248          CorelDRAW Graphics Suite 2025 v26.2.0.170   False\n",
       "249  Kenya pushes for local medical innovations to ...   False\n",
       "\n",
       "[112 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see results, true and false \n",
    "zdf = pd.DataFrame([(z.input_str, z.output) for z in classification_result.results_list], columns=[\"input\", \"output\"])\n",
    "display(zdf.loc[zdf[\"output\"]])\n",
    "zdf.loc[~zdf[\"output\"]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10bdad2f",
   "metadata": {},
   "source": [
    "# Run Agent Worfklow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61eed7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run mock workflow\n",
    "# run rss\n",
    "# go through step by step "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc786240",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsletterAgentState(BaseModel):\n",
    "    \"\"\"Persistent state for the newsletter agent workflow\"\"\"\n",
    "    \n",
    "    # Serializable data storage (DataFrame as list of dicts)\n",
    "    headline_data: List[Dict[str, Any]] = Field(\n",
    "        default_factory=list,\n",
    "        description=\"List of headline dictionaries with columns: title, url, source, timestamp, ai_related, etc.\"\n",
    "    )\n",
    "    \n",
    "    # Source management\n",
    "    sources: Dict[str, Any] = Field(\n",
    "        default_factory=dict,\n",
    "        description=\"Dictionary of source configurations loaded from YAML\"\n",
    "    )\n",
    "    sources_file: str = Field(\n",
    "        default=\"sources.yaml\",\n",
    "        description=\"YAML filename containing source configurations\"\n",
    "    )\n",
    "    \n",
    "    # Workflow progress\n",
    "    current_step: int = Field(default=0, description=\"Current workflow step (0-9)\")\n",
    "    workflow_complete: bool = Field(default=False, description=\"Whether the entire workflow is complete\")\n",
    "    \n",
    "    # Processing results\n",
    "    article_summaries: Dict[str, List[str]] = Field(\n",
    "        default_factory=dict,\n",
    "        description=\"URL -> list of bullet point summaries\"\n",
    "    )\n",
    "    topic_clusters: Dict[str, List[str]] = Field(\n",
    "        default_factory=dict, \n",
    "        description=\"Topic name -> list of article URLs\"\n",
    "    )\n",
    "    newsletter_sections: Dict[str, str] = Field(\n",
    "        default_factory=dict,\n",
    "        description=\"Section name -> section content\"\n",
    "    )\n",
    "    final_newsletter: str = Field(default=\"\", description=\"Final newsletter content\")\n",
    "    \n",
    "    # Configuration\n",
    "    cluster_topics: List[str] = Field(\n",
    "        default_factory=list,\n",
    "        description=\"List of topic names for categorization\"\n",
    "    )\n",
    "    max_edits: int = Field(default=3, description=\"Maximum editing iterations\")\n",
    "    n_browsers: int = Field(default=3, description=\"Number of concurrent browsers\")\n",
    "    \n",
    "    # Helper methods for DataFrame conversion\n",
    "    @property\n",
    "    def headline_df(self) -> 'pd.DataFrame':\n",
    "        \"\"\"Convert stored data back to DataFrame\"\"\"\n",
    "        import pandas as pd\n",
    "        return pd.DataFrame(self.headline_data)\n",
    "    \n",
    "    def update_headlines(self, df: 'pd.DataFrame'):\n",
    "        \"\"\"Update headline data from DataFrame\"\"\"\n",
    "        self.headline_data = df.to_dict('records')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "741be85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WorkflowStatusTool:\n",
    "    \"\"\"Tool to check current workflow status\"\"\"\n",
    "\n",
    "    def __init__(self, workflow_status: WorkflowStatus):\n",
    "        self.workflow_status = workflow_status\n",
    "\n",
    "    async def _check_workflow_status(self, ctx, args: str) -> str:\n",
    "        \"\"\"Get current workflow status report based on persistent state\"\"\"\n",
    "        # Access the persistent state\n",
    "        state: NewsletterAgentState = ctx.context\n",
    "        \n",
    "        # Create a status report based on persistent state\n",
    "        step_names = [\n",
    "            \"step_01_gather_urls\", \"step_02_filter_urls\", \"step_03_download_articles\",\n",
    "            \"step_04_extract_summaries\", \"step_05_cluster_by_topic\", \"step_06_rate_articles\",\n",
    "            \"step_07_select_sections\", \"step_08_draft_sections\", \"step_09_finalize_newsletter\"\n",
    "        ]\n",
    "        \n",
    "        lines = [\n",
    "            \"WORKFLOW STATUS (FROM PERSISTENT STATE)\",\n",
    "            f\"Current Step: {state.current_step}/9\",\n",
    "            f\"Workflow Complete: {state.workflow_complete}\",\n",
    "            f\"Progress: {(state.current_step/9)*100:.1f}%\",\n",
    "            \"\",\n",
    "            \"Step Details:\"\n",
    "        ]\n",
    "        \n",
    "        for i, step_name in enumerate(step_names, 1):\n",
    "            if i <= state.current_step:\n",
    "                status = \"✅ completed\"\n",
    "            elif i == state.current_step + 1:\n",
    "                status = \"➡️ next to execute\"\n",
    "            else:\n",
    "                status = \"⭕ not started\"\n",
    "                \n",
    "            formatted_name = step_name.replace('step_', 'Step ').replace('_', ' ').title()\n",
    "            formatted_name = formatted_name.replace('0', '').replace('  ', ' ')  # Clean up numbering\n",
    "            lines.append(f\"  {formatted_name}: {status}\")\n",
    "        \n",
    "        if state.headline_data:\n",
    "            lines.extend([\n",
    "                \"\",\n",
    "                \"Data Summary:\",\n",
    "                f\"  Total articles: {len(state.headline_data)}\",\n",
    "                f\"  AI-related: {sum(1 for a in state.headline_data if a.get('ai_related') is True)}\",\n",
    "                f\"  Summaries: {len(state.article_summaries)}\",\n",
    "                f\"  Clusters: {len(state.topic_clusters)}\",\n",
    "                f\"  Sections: {len(state.newsletter_sections)}\",\n",
    "            ])\n",
    "        \n",
    "        return \"\\n\".join(lines)\n",
    "\n",
    "    def create_tool(self) -> FunctionTool:\n",
    "        \"\"\"Create a FunctionTool instance following OpenAI Agents SDK conventions\"\"\"\n",
    "        return FunctionTool(\n",
    "            name=\"check_workflow_status\",\n",
    "            description=\"Check the current status of the newsletter workflow and see which steps are completed, in progress, or pending\",\n",
    "            params_json_schema={\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {},\n",
    "                \"required\": []\n",
    "            },\n",
    "            on_invoke_tool=self._check_workflow_status\n",
    "        )\n",
    "\n",
    "\n",
    "class StateInspectionTool:\n",
    "    \"\"\"Tool to inspect detailed persistent state data\"\"\"\n",
    "\n",
    "    def __init__(self, verbose: bool = False):\n",
    "        self.verbose = verbose\n",
    "\n",
    "    async def _inspect_state(self, ctx, args: str) -> str:\n",
    "        \"\"\"Inspect detailed state data for debugging and monitoring\"\"\"\n",
    "        # Access the persistent state\n",
    "        state: NewsletterAgentState = ctx.context\n",
    "\n",
    "        # Create detailed state report\n",
    "        report_lines = [\n",
    "            \"DETAILED STATE INSPECTION\",\n",
    "            \"=\" * 50,\n",
    "            f\"Current Step: {state.current_step}/9\",\n",
    "            f\"Workflow Complete: {state.workflow_complete}\",\n",
    "            f\"Sources File: {state.sources_file}\",\n",
    "            \"\",\n",
    "            \"HEADLINE DATA:\",\n",
    "            f\"  Total articles: {len(state.headline_data)}\",\n",
    "        ]\n",
    "\n",
    "        if state.headline_data:\n",
    "            ai_related = sum(1 for a in state.headline_data if a.get('ai_related') is True)\n",
    "            with_content = sum(1 for a in state.headline_data if a.get('content'))\n",
    "            with_ratings = sum(1 for a in state.headline_data if a.get('quality_rating'))\n",
    "            with_clusters = sum(1 for a in state.headline_data if a.get('cluster_topic'))\n",
    "            \n",
    "            report_lines.extend([\n",
    "                f\"  AI-related: {ai_related}\",\n",
    "                f\"  With content: {with_content}\",\n",
    "                f\"  With ratings: {with_ratings}\",\n",
    "                f\"  With clusters: {with_clusters}\",\n",
    "                f\"  Sources: {len(set(a.get('source', 'Unknown') for a in state.headline_data))}\",\n",
    "            ])\n",
    "\n",
    "        report_lines.extend([\n",
    "            \"\",\n",
    "            \"PROCESSING RESULTS:\",\n",
    "            f\"  Article summaries: {len(state.article_summaries)} articles\",\n",
    "            f\"  Topic clusters: {len(state.topic_clusters)} topics\",\n",
    "            f\"  Newsletter sections: {len(state.newsletter_sections)} sections\",\n",
    "            f\"  Final newsletter: {'Generated' if state.final_newsletter else 'Not created'}\",\n",
    "        ])\n",
    "\n",
    "        if state.topic_clusters:\n",
    "            report_lines.extend([\n",
    "                \"\",\n",
    "                \"TOPIC CLUSTERS:\",\n",
    "            ])\n",
    "            for topic, urls in state.topic_clusters.items():\n",
    "                report_lines.append(f\"  {topic}: {len(urls)} articles\")\n",
    "\n",
    "        if state.newsletter_sections:\n",
    "            report_lines.extend([\n",
    "                \"\",\n",
    "                \"NEWSLETTER SECTIONS:\",\n",
    "            ])\n",
    "            for section_name, section_data in state.newsletter_sections.items():\n",
    "                status = section_data.get('section_status', 'unknown')\n",
    "                word_count = section_data.get('word_count', 0)\n",
    "                article_count = section_data.get('article_count', 0)\n",
    "                report_lines.append(f\"  {section_name}: {status}, {article_count} articles, {word_count} words\")\n",
    "\n",
    "        if state.final_newsletter:\n",
    "            newsletter_words = len(state.final_newsletter.split())\n",
    "            report_lines.extend([\n",
    "                \"\",\n",
    "                \"FINAL NEWSLETTER:\",\n",
    "                f\"  Length: {newsletter_words} words\",\n",
    "                f\"  Preview: {state.final_newsletter[:200]}...\" if len(state.final_newsletter) > 200 else f\"  Content: {state.final_newsletter}\",\n",
    "            ])\n",
    "\n",
    "        return \"\\n\".join(report_lines)\n",
    "\n",
    "    def create_tool(self) -> FunctionTool:\n",
    "        \"\"\"Create a FunctionTool instance following OpenAI Agents SDK conventions\"\"\"\n",
    "        return FunctionTool(\n",
    "            name=\"inspect_state\",\n",
    "            description=\"Inspect detailed persistent state data including article counts, processing results, and content status. Useful for debugging and monitoring workflow progress.\",\n",
    "            params_json_schema={\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {},\n",
    "                \"required\": []\n",
    "            },\n",
    "            on_invoke_tool=self._inspect_state\n",
    "        )\n",
    "\n",
    "\n",
    "class GatherUrlsTool:\n",
    "    \"\"\"Tool for Step 1: Gather URLs from various news sources\"\"\"\n",
    "\n",
    "    def __init__(self, workflow_status: WorkflowStatus, verbose: bool = False):\n",
    "        self.workflow_status = workflow_status  # Keep for UI progress tracking\n",
    "        self.verbose = verbose\n",
    "\n",
    "    async def _gather_urls(self, ctx, args: str) -> str:\n",
    "        \"\"\"Execute Step 1: Gather URLs using persistent state\"\"\"\n",
    "        step_name = \"step_01_gather_urls\"\n",
    "        \n",
    "        # Access the persistent state\n",
    "        state: NewsletterAgentState = ctx.context\n",
    "\n",
    "        # Check if step already completed via persistent state\n",
    "        if state.current_step >= 1:\n",
    "            total_articles = len(state.headline_data)\n",
    "            return f\"Step 1 already completed! Found {total_articles} articles in persistent state.\"\n",
    "\n",
    "        try:\n",
    "            # Update workflow status for UI tracking\n",
    "            self.workflow_status.start_step(step_name)\n",
    "\n",
    "            # Use real RSS fetching from sources.yaml\n",
    "            sources_results = await gather_urls(state.sources_file, max_concurrent=5)\n",
    "\n",
    "            # Process results and store in persistent state\n",
    "            all_articles = []\n",
    "            successful_sources = []\n",
    "            failed_sources = []\n",
    "\n",
    "            for result in sources_results:\n",
    "                if result['status'] == 'success' and result['results']:\n",
    "                    # Add source info to each article\n",
    "                    for article in result['results']:\n",
    "                        article['source_key'] = result['source_key']\n",
    "                        article['ai_related'] = None  # To be determined in step 2\n",
    "                        all_articles.append(article)\n",
    "                    successful_sources.append(result['source_key'])\n",
    "                elif result['status'] == 'not_implemented':\n",
    "                    # Skip HTML/API sources for now\n",
    "                    continue\n",
    "                else:\n",
    "                    failed_sources.append(result['source_key'])\n",
    "\n",
    "            # Store results in persistent state\n",
    "            state.headline_data = all_articles\n",
    "            state.current_step = 1\n",
    "            \n",
    "            # Also update workflow status for UI\n",
    "            self.workflow_status.complete_step(step_name)\n",
    "\n",
    "            if self.verbose:\n",
    "                print(f\"✅ Completed Step 1: Gathered {len(all_articles)} URLs from {len(successful_sources)} RSS sources\")\n",
    "                if failed_sources:\n",
    "                    print(f\"⚠️  Failed sources: {', '.join(failed_sources)}\")\n",
    "\n",
    "            status_msg = f\"✅ Step 1 completed successfully! Gathered {len(all_articles)} articles from {len(successful_sources)} sources (RSS only).\"\n",
    "            if failed_sources:\n",
    "                status_msg += f\" {len(failed_sources)} sources failed or not implemented.\"\n",
    "            \n",
    "            status_msg += f\"\\n\\n📊 Articles stored in persistent state: {len(state.headline_data)}\"\n",
    "            return status_msg\n",
    "\n",
    "        except Exception as e:\n",
    "            self.workflow_status.error_step(step_name, str(e))\n",
    "            return f\"❌ Step 1 failed: {str(e)}\"\n",
    "\n",
    "    def create_tool(self) -> FunctionTool:\n",
    "        \"\"\"Create a FunctionTool instance following OpenAI Agents SDK conventions\"\"\"\n",
    "        return FunctionTool(\n",
    "            name=\"gather_urls\",\n",
    "            description=\"Execute Step 1: Gather URLs and headlines from various news sources. Only use this tool if Step 1 is not already completed.\",\n",
    "            params_json_schema={\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {},\n",
    "                \"required\": []\n",
    "            },\n",
    "            on_invoke_tool=self._gather_urls\n",
    "        )\n",
    "\n",
    "\n",
    "class FilterUrlsTool:\n",
    "    \"\"\"Tool for Step 2: Filter URLs to AI-related content\"\"\"\n",
    "\n",
    "    def __init__(self, workflow_status: WorkflowStatus, verbose: bool = False):\n",
    "        self.workflow_status = workflow_status\n",
    "        self.verbose = verbose\n",
    "\n",
    "    async def _filter_urls(self, ctx, args: str) -> str:\n",
    "        \"\"\"Execute Step 2: Filter URLs using persistent state\"\"\"\n",
    "        step_name = \"step_02_filter_urls\"\n",
    "        \n",
    "        # Access the persistent state\n",
    "        state: NewsletterAgentState = ctx.context\n",
    "\n",
    "        # Check if step already completed via persistent state\n",
    "        if state.current_step >= 2:\n",
    "            ai_related_count = sum(1 for article in state.headline_data if article.get('ai_related') is True)\n",
    "            total_count = len(state.headline_data)\n",
    "            return f\"Step 2 already completed! Filtered {total_count} articles, {ai_related_count} identified as AI-related.\"\n",
    "\n",
    "        # Check if step 1 is completed\n",
    "        if state.current_step < 1 or not state.headline_data:\n",
    "            return f\"❌ Cannot execute Step 2: Step 1 (Gather URLs) must be completed first. Current step: {state.current_step}\"\n",
    "\n",
    "        try:\n",
    "            # Update workflow status for UI tracking\n",
    "            self.workflow_status.start_step(step_name)\n",
    "\n",
    "            # Read headlines from persistent state instead of mock data\n",
    "            total_articles = len(state.headline_data)\n",
    "            \n",
    "            # Mock AI classification - in a real implementation, this would use an AI model\n",
    "            # to analyze titles and descriptions for AI relevance\n",
    "            ai_related_count = 0\n",
    "            for i, article in enumerate(state.headline_data):\n",
    "                # Simple keyword-based mock classification\n",
    "                title_lower = article.get('title', '').lower()\n",
    "                description_lower = article.get('description', '').lower()\n",
    "                \n",
    "                ai_keywords = [\n",
    "                    'artificial intelligence', 'ai', 'machine learning', 'ml', 'deep learning',\n",
    "                    'neural network', 'llm', 'large language model', 'gpt', 'claude', \n",
    "                    'openai', 'anthropic', 'chatbot', 'automation', 'algorithm',\n",
    "                    'computer vision', 'natural language', 'nlp', 'robotics'\n",
    "                ]\n",
    "                \n",
    "                is_ai_related = any(keyword in title_lower or keyword in description_lower \n",
    "                                  for keyword in ai_keywords)\n",
    "                \n",
    "                # Update article with AI classification\n",
    "                state.headline_data[i]['ai_related'] = is_ai_related\n",
    "                if is_ai_related:\n",
    "                    ai_related_count += 1\n",
    "\n",
    "            # Update persistent state\n",
    "            state.current_step = 2\n",
    "            \n",
    "            # Also update workflow status for UI\n",
    "            self.workflow_status.complete_step(step_name)\n",
    "\n",
    "            filter_accuracy = ai_related_count / total_articles if total_articles > 0 else 0\n",
    "\n",
    "            if self.verbose:\n",
    "                print(f\"✅ Completed Step 2: Filtered to {ai_related_count} AI-related headlines from {total_articles} total\")\n",
    "\n",
    "            status_msg = f\"✅ Step 2 completed successfully! Filtered {total_articles} headlines to {ai_related_count} AI-related articles (accuracy: {filter_accuracy:.1%}).\"\n",
    "            status_msg += f\"\\n\\n📊 Results stored in persistent state. Current step: {state.current_step}\"\n",
    "            return status_msg\n",
    "\n",
    "        except Exception as e:\n",
    "            self.workflow_status.error_step(step_name, str(e))\n",
    "            return f\"❌ Step 2 failed: {str(e)}\"\n",
    "\n",
    "    def create_tool(self) -> FunctionTool:\n",
    "        \"\"\"Create a FunctionTool instance following OpenAI Agents SDK conventions\"\"\"\n",
    "        return FunctionTool(\n",
    "            name=\"filter_urls\",\n",
    "            description=\"Execute Step 2: Filter URLs to AI-related content only. Requires Step 1 to be completed first.\",\n",
    "            params_json_schema={\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {},\n",
    "                \"required\": []\n",
    "            },\n",
    "            on_invoke_tool=self._filter_urls\n",
    "        )\n",
    "\n",
    "\n",
    "class DownloadArticlesTool:\n",
    "    \"\"\"Tool for Step 3: Download article content\"\"\"\n",
    "\n",
    "    def __init__(self, workflow_status: WorkflowStatus, verbose: bool = False):\n",
    "        self.workflow_status = workflow_status\n",
    "        self.verbose = verbose\n",
    "\n",
    "    async def _download_articles(self, ctx, args: str) -> str:\n",
    "        \"\"\"Execute Step 3: Download Articles using persistent state\"\"\"\n",
    "        step_name = \"step_03_download_articles\"\n",
    "        \n",
    "        # Access the persistent state\n",
    "        state: NewsletterAgentState = ctx.context\n",
    "\n",
    "        # Check if step already completed via persistent state\n",
    "        if state.current_step >= 3:\n",
    "            ai_articles = [article for article in state.headline_data if article.get('ai_related') is True]\n",
    "            downloaded_count = sum(1 for article in ai_articles if article.get('content'))\n",
    "            return f\"Step 3 already completed! Downloaded content for {downloaded_count} AI-related articles.\"\n",
    "\n",
    "        # Check if step 2 is completed\n",
    "        if state.current_step < 2:\n",
    "            return f\"❌ Cannot execute Step 3: Step 2 (Filter URLs) must be completed first. Current step: {state.current_step}\"\n",
    "\n",
    "        try:\n",
    "            # Update workflow status for UI tracking\n",
    "            self.workflow_status.start_step(step_name)\n",
    "\n",
    "            # Get AI-related articles from persistent state\n",
    "            ai_articles = [article for article in state.headline_data if article.get('ai_related') is True]\n",
    "            \n",
    "            if not ai_articles:\n",
    "                return f\"❌ No AI-related articles found to download. Please run step 2 first.\"\n",
    "\n",
    "            # Mock content download - in a real implementation, this would fetch actual article content\n",
    "            successful_downloads = 0\n",
    "            total_length = 0\n",
    "            \n",
    "            for article in state.headline_data:\n",
    "                if article.get('ai_related') is True:\n",
    "                    # Simulate downloading article content\n",
    "                    # In reality, this would use web scraping or API calls\n",
    "                    mock_content = f\"Mock article content for: {article.get('title', 'Unknown title')}\\n\\n\"\n",
    "                    mock_content += f\"This is placeholder content that would normally be extracted from {article.get('url', 'unknown URL')}.\\n\"\n",
    "                    mock_content += f\"The article covers topics related to AI and technology as indicated by the title and description.\\n\"\n",
    "                    mock_content += f\"Source: {article.get('source', 'Unknown source')}\\n\"\n",
    "                    \n",
    "                    # Add content to the article data\n",
    "                    article['content'] = mock_content\n",
    "                    article['download_timestamp'] = datetime.now().isoformat()\n",
    "                    article['content_length'] = len(mock_content)\n",
    "                    \n",
    "                    successful_downloads += 1\n",
    "                    total_length += len(mock_content)\n",
    "\n",
    "            # Calculate stats\n",
    "            download_success_rate = successful_downloads / len(ai_articles) if ai_articles else 0\n",
    "            avg_article_length = total_length / successful_downloads if successful_downloads > 0 else 0\n",
    "\n",
    "            # Update persistent state\n",
    "            state.current_step = 3\n",
    "            \n",
    "            # Also update workflow status for UI\n",
    "            self.workflow_status.complete_step(step_name)\n",
    "\n",
    "            if self.verbose:\n",
    "                print(f\"✅ Completed Step 3: Downloaded {successful_downloads} AI-related articles\")\n",
    "\n",
    "            status_msg = f\"✅ Step 3 completed successfully! Downloaded {successful_downloads} AI-related articles with {download_success_rate:.0%} success rate.\"\n",
    "            status_msg += f\"\\n📊 Average article length: {avg_article_length:.0f} characters\"\n",
    "            status_msg += f\"\\n🔗 Content stored in persistent state. Current step: {state.current_step}\"\n",
    "            return status_msg\n",
    "\n",
    "        except Exception as e:\n",
    "            self.workflow_status.error_step(step_name, str(e))\n",
    "            return f\"❌ Step 3 failed: {str(e)}\"\n",
    "\n",
    "    def create_tool(self) -> FunctionTool:\n",
    "        \"\"\"Create a FunctionTool instance following OpenAI Agents SDK conventions\"\"\"\n",
    "        return FunctionTool(\n",
    "            name=\"download_articles\",\n",
    "            description=\"Execute Step 3: Download full article content from filtered URLs. Requires Step 2 to be completed first.\",\n",
    "            params_json_schema={\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {},\n",
    "                \"required\": []\n",
    "            },\n",
    "            on_invoke_tool=self._download_articles\n",
    "        )\n",
    "\n",
    "\n",
    "class ExtractSummariesTool:\n",
    "    \"\"\"Tool for Step 4: Extract article summaries\"\"\"\n",
    "\n",
    "    def __init__(self, workflow_status: WorkflowStatus, verbose: bool = False):\n",
    "        self.workflow_status = workflow_status\n",
    "        self.verbose = verbose\n",
    "\n",
    "    async def _extract_summaries(self, ctx, args: str) -> str:\n",
    "        \"\"\"Execute Step 4: Extract Summaries using persistent state\"\"\"\n",
    "        step_name = \"step_04_extract_summaries\"\n",
    "        \n",
    "        # Access the persistent state\n",
    "        state: NewsletterAgentState = ctx.context\n",
    "\n",
    "        # Check if step already completed via persistent state\n",
    "        if state.current_step >= 4:\n",
    "            summary_count = len([url for url in state.article_summaries.keys() if state.article_summaries[url]])\n",
    "            return f\"Step 4 already completed! Generated summaries for {summary_count} articles.\"\n",
    "\n",
    "        # Check if step 3 is completed\n",
    "        if state.current_step < 3:\n",
    "            return f\"❌ Cannot execute Step 4: Step 3 (Download Articles) must be completed first. Current step: {state.current_step}\"\n",
    "\n",
    "        try:\n",
    "            # Update workflow status for UI tracking\n",
    "            self.workflow_status.start_step(step_name)\n",
    "\n",
    "            # Get articles with content from persistent state\n",
    "            articles_with_content = [\n",
    "                article for article in state.headline_data \n",
    "                if article.get('ai_related') is True and article.get('content')\n",
    "            ]\n",
    "            \n",
    "            if not articles_with_content:\n",
    "                return f\"❌ No downloaded AI-related articles found to summarize. Please run step 3 first.\"\n",
    "\n",
    "            # Clear existing summaries if rerunning\n",
    "            state.article_summaries = {}\n",
    "            \n",
    "            # Generate summaries for each article\n",
    "            articles_summarized = 0\n",
    "            total_bullets = 0\n",
    "            \n",
    "            for article in articles_with_content:\n",
    "                url = article.get('url', f\"article_{articles_summarized}\")\n",
    "                title = article.get('title', 'Unknown title')\n",
    "                content = article.get('content', '')\n",
    "                \n",
    "                # Mock summary generation - in a real implementation, this would use an AI model\n",
    "                # to create bullet point summaries from the full article content\n",
    "                mock_summary = [\n",
    "                    f\"Key insight from '{title[:50]}...' - Main technological development discussed\",\n",
    "                    f\"Business implications or market impact highlighted in the article\",\n",
    "                    f\"Future outlook or expert predictions mentioned in the content\"\n",
    "                ]\n",
    "                \n",
    "                # Store summary in persistent state\n",
    "                state.article_summaries[url] = mock_summary\n",
    "                articles_summarized += 1\n",
    "                total_bullets += len(mock_summary)\n",
    "                \n",
    "                # Add summary reference to article data as well\n",
    "                article['summary_bullets'] = len(mock_summary)\n",
    "                article['summary_timestamp'] = datetime.now().isoformat()\n",
    "\n",
    "            # Calculate stats\n",
    "            avg_bullets_per_article = total_bullets / articles_summarized if articles_summarized > 0 else 0\n",
    "            summary_quality_score = 0.89  # Mock quality score\n",
    "\n",
    "            # Update persistent state\n",
    "            state.current_step = 4\n",
    "            \n",
    "            # Also update workflow status for UI\n",
    "            self.workflow_status.complete_step(step_name)\n",
    "\n",
    "            if self.verbose:\n",
    "                print(f\"✅ Completed Step 4: Created summaries for {articles_summarized} articles\")\n",
    "\n",
    "            status_msg = f\"✅ Step 4 completed successfully! Generated {avg_bullets_per_article:.1f}-bullet summaries for {articles_summarized} articles.\"\n",
    "            status_msg += f\"\\n📝 Quality score: {summary_quality_score:.1%}\"\n",
    "            status_msg += f\"\\n💾 Summaries stored in persistent state. Current step: {state.current_step}\"\n",
    "            return status_msg\n",
    "\n",
    "        except Exception as e:\n",
    "            self.workflow_status.error_step(step_name, str(e))\n",
    "            return f\"❌ Step 4 failed: {str(e)}\"\n",
    "\n",
    "    def create_tool(self) -> FunctionTool:\n",
    "        \"\"\"Create a FunctionTool instance following OpenAI Agents SDK conventions\"\"\"\n",
    "        return FunctionTool(\n",
    "            name=\"extract_summaries\",\n",
    "            description=\"Execute Step 4: Create bullet point summaries of each downloaded article. Requires Step 3 to be completed first.\",\n",
    "            params_json_schema={\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {},\n",
    "                \"required\": []\n",
    "            },\n",
    "            on_invoke_tool=self._extract_summaries\n",
    "        )\n",
    "\n",
    "\n",
    "class ClusterByTopicTool:\n",
    "    \"\"\"Tool for Step 5: Cluster articles by topic\"\"\"\n",
    "\n",
    "    def __init__(self, workflow_status: WorkflowStatus, verbose: bool = False):\n",
    "        self.workflow_status = workflow_status\n",
    "        self.verbose = verbose\n",
    "\n",
    "    async def _cluster_by_topic(self, ctx, args: str) -> str:\n",
    "        \"\"\"Execute Step 5: Cluster By Topic using persistent state\"\"\"\n",
    "        step_name = \"step_05_cluster_by_topic\"\n",
    "        \n",
    "        # Access the persistent state\n",
    "        state: NewsletterAgentState = ctx.context\n",
    "\n",
    "        # Check if step already completed via persistent state\n",
    "        if state.current_step >= 5:\n",
    "            cluster_count = len(state.topic_clusters)\n",
    "            total_articles = sum(len(articles) for articles in state.topic_clusters.values())\n",
    "            return f\"Step 5 already completed! Created {cluster_count} topic clusters with {total_articles} articles.\"\n",
    "\n",
    "        # Check if step 4 is completed\n",
    "        if state.current_step < 4:\n",
    "            return f\"❌ Cannot execute Step 5: Step 4 (Extract Summaries) must be completed first. Current step: {state.current_step}\"\n",
    "\n",
    "        try:\n",
    "            # Update workflow status for UI tracking\n",
    "            self.workflow_status.start_step(step_name)\n",
    "\n",
    "            # Get articles with summaries from persistent state\n",
    "            articles_with_summaries = [\n",
    "                article for article in state.headline_data \n",
    "                if article.get('ai_related') is True and \n",
    "                article.get('url') in state.article_summaries\n",
    "            ]\n",
    "            \n",
    "            if not articles_with_summaries:\n",
    "                return f\"❌ No summarized articles found to cluster. Please run step 4 first.\"\n",
    "\n",
    "            # Clear existing clusters if rerunning\n",
    "            state.topic_clusters = {}\n",
    "            \n",
    "            # Mock clustering logic - in a real implementation, this would use NLP/ML\n",
    "            # to group articles by semantic similarity of their titles and summaries\n",
    "            predefined_topics = [\n",
    "                \"LLM Advances\", \"AI Safety & Ethics\", \"Business AI Applications\", \n",
    "                \"Research Breakthroughs\", \"Industry News\", \"Other AI Topics\"\n",
    "            ]\n",
    "            \n",
    "            # Initialize empty clusters\n",
    "            for topic in predefined_topics:\n",
    "                state.topic_clusters[topic] = []\n",
    "            \n",
    "            # Simple keyword-based clustering\n",
    "            topic_keywords = {\n",
    "                \"LLM Advances\": [\"llm\", \"large language model\", \"gpt\", \"claude\", \"language model\", \"chatbot\", \"chat\"],\n",
    "                \"AI Safety & Ethics\": [\"safety\", \"ethics\", \"bias\", \"fairness\", \"responsible\", \"trust\", \"alignment\"],\n",
    "                \"Business AI Applications\": [\"business\", \"enterprise\", \"productivity\", \"automation\", \"workflow\", \"commercial\"],\n",
    "                \"Research Breakthroughs\": [\"research\", \"breakthrough\", \"paper\", \"study\", \"academic\", \"university\", \"science\"],\n",
    "                \"Industry News\": [\"company\", \"startup\", \"funding\", \"acquisition\", \"partnership\", \"launch\", \"release\"],\n",
    "                \"Other AI Topics\": []  # Catch-all\n",
    "            }\n",
    "            \n",
    "            for article in articles_with_summaries:\n",
    "                url = article.get('url', '')\n",
    "                title_lower = article.get('title', '').lower()\n",
    "                description_lower = article.get('description', '').lower()\n",
    "                \n",
    "                # Find best matching topic\n",
    "                best_topic = \"Other AI Topics\"  # Default\n",
    "                max_matches = 0\n",
    "                \n",
    "                for topic, keywords in topic_keywords.items():\n",
    "                    if topic == \"Other AI Topics\":\n",
    "                        continue\n",
    "                        \n",
    "                    matches = sum(1 for keyword in keywords \n",
    "                                if keyword in title_lower or keyword in description_lower)\n",
    "                    \n",
    "                    if matches > max_matches:\n",
    "                        max_matches = matches\n",
    "                        best_topic = topic\n",
    "                \n",
    "                # Add article URL to the appropriate cluster\n",
    "                state.topic_clusters[best_topic].append(url)\n",
    "                \n",
    "                # Also update the article with cluster info\n",
    "                article['cluster_topic'] = best_topic\n",
    "                article['cluster_timestamp'] = datetime.now().isoformat()\n",
    "\n",
    "            # Remove empty clusters\n",
    "            state.topic_clusters = {\n",
    "                topic: articles for topic, articles in state.topic_clusters.items() \n",
    "                if articles\n",
    "            }\n",
    "            \n",
    "            # Calculate stats\n",
    "            total_clusters = len(state.topic_clusters)\n",
    "            total_articles = sum(len(articles) for articles in state.topic_clusters.values())\n",
    "            cluster_coherence_score = 0.84  # Mock coherence score\n",
    "\n",
    "            # Update persistent state\n",
    "            state.current_step = 5\n",
    "            \n",
    "            # Also update workflow status for UI\n",
    "            self.workflow_status.complete_step(step_name)\n",
    "\n",
    "            if self.verbose:\n",
    "                print(f\"✅ Completed Step 5: Created {total_clusters} topic clusters\")\n",
    "\n",
    "            status_msg = f\"✅ Step 5 completed successfully! Organized {total_articles} articles into {total_clusters} topic clusters.\"\n",
    "            status_msg += f\"\\n📊 Cluster coherence score: {cluster_coherence_score:.1%}\"\n",
    "            status_msg += f\"\\n🏷️ Topics: {', '.join(state.topic_clusters.keys())}\"\n",
    "            status_msg += f\"\\n💾 Clusters stored in persistent state. Current step: {state.current_step}\"\n",
    "            return status_msg\n",
    "\n",
    "        except Exception as e:\n",
    "            self.workflow_status.error_step(step_name, str(e))\n",
    "            return f\"❌ Step 5 failed: {str(e)}\"\n",
    "\n",
    "    def create_tool(self) -> FunctionTool:\n",
    "        \"\"\"Create a FunctionTool instance following OpenAI Agents SDK conventions\"\"\"\n",
    "        return FunctionTool(\n",
    "            name=\"cluster_by_topic\",\n",
    "            description=\"Execute Step 5: Group articles by thematic topics using clustering. Requires Step 4 to be completed first.\",\n",
    "            params_json_schema={\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {},\n",
    "                \"required\": []\n",
    "            },\n",
    "            on_invoke_tool=self._cluster_by_topic\n",
    "        )\n",
    "\n",
    "\n",
    "class RateArticlesTool:\n",
    "    \"\"\"Tool for Step 6: Rate article quality and importance\"\"\"\n",
    "\n",
    "    def __init__(self, workflow_status: WorkflowStatus, verbose: bool = False):\n",
    "        self.workflow_status = workflow_status\n",
    "        self.verbose = verbose\n",
    "\n",
    "    async def _rate_articles(self, ctx, args: str) -> str:\n",
    "        \"\"\"Execute Step 6: Rate Articles using persistent state\"\"\"\n",
    "        step_name = \"step_06_rate_articles\"\n",
    "        \n",
    "        # Access the persistent state\n",
    "        state: NewsletterAgentState = ctx.context\n",
    "\n",
    "        # Check if step already completed via persistent state\n",
    "        if state.current_step >= 6:\n",
    "            rated_articles = [article for article in state.headline_data if article.get('quality_rating')]\n",
    "            avg_rating = sum(article.get('quality_rating', 0) for article in rated_articles) / len(rated_articles) if rated_articles else 0\n",
    "            return f\"Step 6 already completed! Rated {len(rated_articles)} articles with average rating {avg_rating:.1f}/10.\"\n",
    "\n",
    "        # Check if step 5 is completed\n",
    "        if state.current_step < 5:\n",
    "            return f\"❌ Cannot execute Step 6: Step 5 (Cluster By Topic) must be completed first. Current step: {state.current_step}\"\n",
    "\n",
    "        try:\n",
    "            # Update workflow status for UI tracking\n",
    "            self.workflow_status.start_step(step_name)\n",
    "\n",
    "            # Get clustered articles from persistent state\n",
    "            clustered_articles = [\n",
    "                article for article in state.headline_data \n",
    "                if article.get('ai_related') is True and article.get('cluster_topic')\n",
    "            ]\n",
    "            \n",
    "            if not clustered_articles:\n",
    "                return f\"❌ No clustered articles found to rate. Please run step 5 first.\"\n",
    "\n",
    "            # Rate each article based on mock criteria\n",
    "            articles_rated = 0\n",
    "            total_rating = 0\n",
    "            high_quality_count = 0\n",
    "            \n",
    "            for article in clustered_articles:\n",
    "                # Mock rating logic - in reality, this would use AI to evaluate:\n",
    "                # - Content quality, originality, depth\n",
    "                # - Source credibility\n",
    "                # - Relevance to AI community\n",
    "                # - Timeliness and newsworthiness\n",
    "                \n",
    "                title_length = len(article.get('title', ''))\n",
    "                has_description = bool(article.get('description', ''))\n",
    "                source_quality = 8 if article.get('source') in ['Techmeme', 'Ars Technica', 'The Verge'] else 6\n",
    "                cluster_bonus = 2 if article.get('cluster_topic') != 'Other AI Topics' else 0\n",
    "                \n",
    "                # Calculate mock quality rating (1-10)\n",
    "                base_rating = 5\n",
    "                if title_length > 50: base_rating += 1\n",
    "                if has_description: base_rating += 1\n",
    "                rating = min(10, base_rating + (source_quality - 6) + cluster_bonus)\n",
    "                \n",
    "                # Add some randomness to make it more realistic\n",
    "                import random\n",
    "                rating = max(1, min(10, rating + random.uniform(-1, 1)))\n",
    "                \n",
    "                # Store rating in article data\n",
    "                article['quality_rating'] = round(rating, 1)\n",
    "                article['rating_timestamp'] = datetime.now().isoformat()\n",
    "                \n",
    "                articles_rated += 1\n",
    "                total_rating += rating\n",
    "                if rating >= 7.0:\n",
    "                    high_quality_count += 1\n",
    "\n",
    "            # Calculate stats\n",
    "            avg_rating = total_rating / articles_rated if articles_rated > 0 else 0\n",
    "\n",
    "            # Update persistent state\n",
    "            state.current_step = 6\n",
    "            \n",
    "            # Also update workflow status for UI\n",
    "            self.workflow_status.complete_step(step_name)\n",
    "\n",
    "            if self.verbose:\n",
    "                print(f\"✅ Completed Step 6: Rated {articles_rated} articles\")\n",
    "\n",
    "            status_msg = f\"✅ Step 6 completed successfully! Rated {articles_rated} articles with average rating {avg_rating:.1f}/10.\"\n",
    "            status_msg += f\"\\n⭐ High quality articles (≥7.0): {high_quality_count}\"\n",
    "            status_msg += f\"\\n💾 Ratings stored in persistent state. Current step: {state.current_step}\"\n",
    "            return status_msg\n",
    "\n",
    "        except Exception as e:\n",
    "            self.workflow_status.error_step(step_name, str(e))\n",
    "            return f\"❌ Step 6 failed: {str(e)}\"\n",
    "\n",
    "    def create_tool(self) -> FunctionTool:\n",
    "        \"\"\"Create a FunctionTool instance following OpenAI Agents SDK conventions\"\"\"\n",
    "        return FunctionTool(\n",
    "            name=\"rate_articles\",\n",
    "            description=\"Execute Step 6: Evaluate article quality and importance with ratings. Requires Step 5 to be completed first.\",\n",
    "            params_json_schema={\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {},\n",
    "                \"required\": []\n",
    "            },\n",
    "            on_invoke_tool=self._rate_articles\n",
    "        )\n",
    "\n",
    "\n",
    "class SelectSectionsTool:\n",
    "    \"\"\"Tool for Step 7: Select newsletter sections\"\"\"\n",
    "\n",
    "    def __init__(self, workflow_status: WorkflowStatus, verbose: bool = False):\n",
    "        self.workflow_status = workflow_status\n",
    "        self.verbose = verbose\n",
    "\n",
    "    async def _select_sections(self, ctx, args: str) -> str:\n",
    "        \"\"\"Execute Step 7: Select Sections using persistent state\"\"\"\n",
    "        step_name = \"step_07_select_sections\"\n",
    "        \n",
    "        # Access the persistent state\n",
    "        state: NewsletterAgentState = ctx.context\n",
    "\n",
    "        # Check if step already completed via persistent state\n",
    "        if state.current_step >= 7:\n",
    "            section_count = len(state.newsletter_sections)\n",
    "            return f\"Step 7 already completed! Created {section_count} newsletter sections.\"\n",
    "\n",
    "        # Check if step 6 is completed\n",
    "        if state.current_step < 6:\n",
    "            return f\"❌ Cannot execute Step 7: Step 6 (Rate Articles) must be completed first. Current step: {state.current_step}\"\n",
    "\n",
    "        try:\n",
    "            # Update workflow status for UI tracking\n",
    "            self.workflow_status.start_step(step_name)\n",
    "\n",
    "            # Get rated articles from persistent state\n",
    "            rated_articles = [\n",
    "                article for article in state.headline_data \n",
    "                if article.get('ai_related') is True and article.get('quality_rating')\n",
    "            ]\n",
    "            \n",
    "            if not rated_articles:\n",
    "                return f\"❌ No rated articles found to organize into sections. Please run step 6 first.\"\n",
    "\n",
    "            # Clear existing sections if rerunning\n",
    "            state.newsletter_sections = {}\n",
    "            \n",
    "            # Create newsletter sections based on topic clusters and ratings\n",
    "            # Use existing topic clusters but prioritize high-quality articles\n",
    "            high_quality_articles = [a for a in rated_articles if a.get('quality_rating', 0) >= 7.0]\n",
    "            medium_quality_articles = [a for a in rated_articles if 5.0 <= a.get('quality_rating', 0) < 7.0]\n",
    "            \n",
    "            # Group articles by cluster topic and select best ones for each section\n",
    "            cluster_sections = {}\n",
    "            for article in high_quality_articles + medium_quality_articles:\n",
    "                cluster = article.get('cluster_topic', 'Other AI Topics')\n",
    "                if cluster not in cluster_sections:\n",
    "                    cluster_sections[cluster] = []\n",
    "                cluster_sections[cluster].append(article)\n",
    "            \n",
    "            # Create newsletter sections with article assignments\n",
    "            articles_assigned = 0\n",
    "            for cluster, articles in cluster_sections.items():\n",
    "                if not articles:\n",
    "                    continue\n",
    "                    \n",
    "                # Sort articles by rating (highest first) and take top articles\n",
    "                sorted_articles = sorted(articles, key=lambda x: x.get('quality_rating', 0), reverse=True)\n",
    "                top_articles = sorted_articles[:5]  # Max 5 articles per section\n",
    "                \n",
    "                # Create section outline (will be filled in step 8)\n",
    "                section_content = {\n",
    "                    'title': cluster,\n",
    "                    'article_count': len(top_articles),\n",
    "                    'articles': [{\n",
    "                        'url': article.get('url'),\n",
    "                        'title': article.get('title'),\n",
    "                        'rating': article.get('quality_rating'),\n",
    "                        'source': article.get('source')\n",
    "                    } for article in top_articles],\n",
    "                    'section_status': 'selected',\n",
    "                    'timestamp': datetime.now().isoformat()\n",
    "                }\n",
    "                \n",
    "                state.newsletter_sections[cluster] = section_content\n",
    "                articles_assigned += len(top_articles)\n",
    "\n",
    "            # Update persistent state\n",
    "            state.current_step = 7\n",
    "            \n",
    "            # Also update workflow status for UI\n",
    "            self.workflow_status.complete_step(step_name)\n",
    "\n",
    "            if self.verbose:\n",
    "                print(f\"✅ Completed Step 7: Created {len(state.newsletter_sections)} newsletter sections\")\n",
    "\n",
    "            status_msg = f\"✅ Step 7 completed successfully! Organized content into {len(state.newsletter_sections)} sections with {articles_assigned} articles assigned.\"\n",
    "            status_msg += f\"\\n📑 Sections: {', '.join(state.newsletter_sections.keys())}\"\n",
    "            status_msg += f\"\\n💾 Section plan stored in persistent state. Current step: {state.current_step}\"\n",
    "            return status_msg\n",
    "\n",
    "        except Exception as e:\n",
    "            self.workflow_status.error_step(step_name, str(e))\n",
    "            return f\"❌ Step 7 failed: {str(e)}\"\n",
    "\n",
    "    def create_tool(self) -> FunctionTool:\n",
    "        \"\"\"Create a FunctionTool instance following OpenAI Agents SDK conventions\"\"\"\n",
    "        return FunctionTool(\n",
    "            name=\"select_sections\",\n",
    "            description=\"Execute Step 7: Organize articles into newsletter sections based on topics and ratings. Requires Step 6 to be completed first.\",\n",
    "            params_json_schema={\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {},\n",
    "                \"required\": []\n",
    "            },\n",
    "            on_invoke_tool=self._select_sections\n",
    "        )\n",
    "\n",
    "\n",
    "class DraftSectionsTool:\n",
    "    \"\"\"Tool for Step 8: Draft section content\"\"\"\n",
    "\n",
    "    def __init__(self, workflow_status: WorkflowStatus, verbose: bool = False):\n",
    "        self.workflow_status = workflow_status\n",
    "        self.verbose = verbose\n",
    "\n",
    "    async def _draft_sections(self, ctx, args: str) -> str:\n",
    "        \"\"\"Execute Step 8: Draft Sections using persistent state\"\"\"\n",
    "        step_name = \"step_08_draft_sections\"\n",
    "        \n",
    "        # Access the persistent state\n",
    "        state: NewsletterAgentState = ctx.context\n",
    "\n",
    "        # Check if step already completed via persistent state\n",
    "        if state.current_step >= 8:\n",
    "            drafted_sections = [s for s in state.newsletter_sections.values() if s.get('content')]\n",
    "            total_words = sum(len(s.get('content', '').split()) for s in drafted_sections)\n",
    "            return f\"Step 8 already completed! Drafted {len(drafted_sections)} sections with {total_words} total words.\"\n",
    "\n",
    "        # Check if step 7 is completed\n",
    "        if state.current_step < 7:\n",
    "            return f\"❌ Cannot execute Step 8: Step 7 (Select Sections) must be completed first. Current step: {state.current_step}\"\n",
    "\n",
    "        try:\n",
    "            # Update workflow status for UI tracking\n",
    "            self.workflow_status.start_step(step_name)\n",
    "\n",
    "            # Get section plans from persistent state\n",
    "            if not state.newsletter_sections:\n",
    "                return f\"❌ No newsletter sections found to draft. Please run step 7 first.\"\n",
    "\n",
    "            # Draft content for each section\n",
    "            sections_drafted = 0\n",
    "            total_words = 0\n",
    "            \n",
    "            for section_name, section_data in state.newsletter_sections.items():\n",
    "                if section_data.get('section_status') != 'selected':\n",
    "                    continue\n",
    "                    \n",
    "                articles = section_data.get('articles', [])\n",
    "                if not articles:\n",
    "                    continue\n",
    "                \n",
    "                # Mock section content generation - in reality, this would use AI\n",
    "                # to create engaging newsletter content from article summaries\n",
    "                section_content = f\"## {section_name}\\n\\n\"\n",
    "                \n",
    "                # Add intro paragraph\n",
    "                intro_templates = {\n",
    "                    'LLM Advances': \"The latest developments in large language models continue to push the boundaries of what's possible in AI.\",\n",
    "                    'AI Safety & Ethics': \"Important discussions around responsible AI development and deployment are shaping the future of the field.\",\n",
    "                    'Business AI Applications': \"Companies are finding innovative ways to integrate AI into their products and workflows.\",\n",
    "                    'Research Breakthroughs': \"Academic researchers are making significant strides in advancing our understanding of artificial intelligence.\",\n",
    "                    'Industry News': \"The AI industry continues to evolve with new partnerships, funding rounds, and product launches.\"\n",
    "                }\n",
    "                \n",
    "                intro = intro_templates.get(section_name, f\"Here are the latest updates in {section_name.lower()}.\")\n",
    "                section_content += f\"{intro}\\n\\n\"\n",
    "                \n",
    "                # Add article summaries\n",
    "                for i, article in enumerate(articles[:3]):  # Top 3 articles per section\n",
    "                    article_url = article.get('url', '')\n",
    "                    article_title = article.get('title', 'Unknown Title')\n",
    "                    article_source = article.get('source', 'Unknown Source')\n",
    "                    \n",
    "                    # Get the actual summary from state if available\n",
    "                    summary_bullets = state.article_summaries.get(article_url, [\n",
    "                        f\"Key insights from this {section_name.lower()} article\",\n",
    "                        f\"Important implications for the AI community\",\n",
    "                        f\"Notable developments worth following\"\n",
    "                    ])\n",
    "                    \n",
    "                    section_content += f\"### {article_title}\\n\"\n",
    "                    section_content += f\"*Source: {article_source}*\\n\\n\"\n",
    "                    \n",
    "                    for bullet in summary_bullets:\n",
    "                        section_content += f\"- {bullet}\\n\"\n",
    "                    \n",
    "                    section_content += f\"\\n[Read more]({article_url})\\n\\n\"\n",
    "                \n",
    "                # Store the drafted content\n",
    "                state.newsletter_sections[section_name]['content'] = section_content\n",
    "                state.newsletter_sections[section_name]['section_status'] = 'drafted'\n",
    "                state.newsletter_sections[section_name]['draft_timestamp'] = datetime.now().isoformat()\n",
    "                state.newsletter_sections[section_name]['word_count'] = len(section_content.split())\n",
    "                \n",
    "                sections_drafted += 1\n",
    "                total_words += len(section_content.split())\n",
    "\n",
    "            # Calculate average words per section\n",
    "            avg_words_per_section = total_words / sections_drafted if sections_drafted > 0 else 0\n",
    "\n",
    "            # Update persistent state\n",
    "            state.current_step = 8\n",
    "            \n",
    "            # Also update workflow status for UI\n",
    "            self.workflow_status.complete_step(step_name)\n",
    "\n",
    "            if self.verbose:\n",
    "                print(f\"✅ Completed Step 8: Drafted {sections_drafted} sections\")\n",
    "\n",
    "            status_msg = f\"✅ Step 8 completed successfully! Drafted {sections_drafted} sections with {total_words} total words.\"\n",
    "            status_msg += f\"\\n📝 Average words per section: {avg_words_per_section:.0f}\"\n",
    "            status_msg += f\"\\n💾 Section content stored in persistent state. Current step: {state.current_step}\"\n",
    "            return status_msg\n",
    "\n",
    "        except Exception as e:\n",
    "            self.workflow_status.error_step(step_name, str(e))\n",
    "            return f\"❌ Step 8 failed: {str(e)}\"\n",
    "\n",
    "    def create_tool(self) -> FunctionTool:\n",
    "        \"\"\"Create a FunctionTool instance following OpenAI Agents SDK conventions\"\"\"\n",
    "        return FunctionTool(\n",
    "            name=\"draft_sections\",\n",
    "            description=\"Execute Step 8: Write engaging content for each newsletter section. Requires Step 7 to be completed first.\",\n",
    "            params_json_schema={\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {},\n",
    "                \"required\": []\n",
    "            },\n",
    "            on_invoke_tool=self._draft_sections\n",
    "        )\n",
    "\n",
    "\n",
    "class FinalizeNewsletterTool:\n",
    "    \"\"\"Tool for Step 9: Finalize complete newsletter\"\"\"\n",
    "\n",
    "    def __init__(self, workflow_status: WorkflowStatus, verbose: bool = False):\n",
    "        self.workflow_status = workflow_status\n",
    "        self.verbose = verbose\n",
    "\n",
    "    async def _finalize_newsletter(self, ctx, args: str) -> str:\n",
    "        \"\"\"Execute Step 9: Finalize Newsletter using persistent state\"\"\"\n",
    "        step_name = \"step_09_finalize_newsletter\"\n",
    "        \n",
    "        # Access the persistent state\n",
    "        state: NewsletterAgentState = ctx.context\n",
    "\n",
    "        # Check if step already completed via persistent state\n",
    "        if state.current_step >= 9:\n",
    "            newsletter_length = len(state.final_newsletter.split()) if state.final_newsletter else 0\n",
    "            sections_count = len([s for s in state.newsletter_sections.values() if s.get('content')])\n",
    "            return f\"Step 9 already completed! Newsletter finalized with {sections_count} sections and {newsletter_length} words.\"\n",
    "\n",
    "        # Check if step 8 is completed\n",
    "        if state.current_step < 8:\n",
    "            return f\"❌ Cannot execute Step 9: Step 8 (Draft Sections) must be completed first. Current step: {state.current_step}\"\n",
    "\n",
    "        try:\n",
    "            # Update workflow status for UI tracking\n",
    "            self.workflow_status.start_step(step_name)\n",
    "\n",
    "            # Get drafted sections from persistent state\n",
    "            drafted_sections = {\n",
    "                name: data for name, data in state.newsletter_sections.items()\n",
    "                if data.get('section_status') == 'drafted' and data.get('content')\n",
    "            }\n",
    "            \n",
    "            if not drafted_sections:\n",
    "                return f\"❌ No drafted sections found to finalize. Please run step 8 first.\"\n",
    "\n",
    "            # Create the final newsletter by combining all sections\n",
    "            today = datetime.now().strftime(\"%B %d, %Y\")\n",
    "            \n",
    "            newsletter_content = f\"# AI News Digest - {today}\\n\\n\"\n",
    "            newsletter_content += f\"*Curated insights from the latest in artificial intelligence*\\n\\n\"\n",
    "            newsletter_content += f\"---\\n\\n\"\n",
    "            \n",
    "            # Add table of contents\n",
    "            newsletter_content += \"## Table of Contents\\n\\n\"\n",
    "            for i, section_name in enumerate(drafted_sections.keys(), 1):\n",
    "                newsletter_content += f\"{i}. [{section_name}](#{section_name.lower().replace(' ', '-').replace('&', 'and')})\\n\"\n",
    "            newsletter_content += \"\\n---\\n\\n\"\n",
    "            \n",
    "            # Add each section content\n",
    "            for section_name, section_data in drafted_sections.items():\n",
    "                newsletter_content += section_data.get('content', '')\n",
    "                newsletter_content += \"\\n---\\n\\n\"\n",
    "            \n",
    "            # Add footer\n",
    "            newsletter_content += \"## About This Newsletter\\n\\n\"\n",
    "            newsletter_content += \"This AI News Digest was automatically curated using our intelligent newsletter agent. \"\n",
    "            newsletter_content += f\"We analyzed {len(state.headline_data)} articles from {len(set(a.get('source', '') for a in state.headline_data))} sources \"\n",
    "            newsletter_content += f\"to bring you the most relevant AI developments.\\n\\n\"\n",
    "            newsletter_content += f\"*Generated on {today}*\\n\"\n",
    "            \n",
    "            # Store the final newsletter\n",
    "            state.final_newsletter = newsletter_content\n",
    "            \n",
    "            # Calculate final stats\n",
    "            newsletter_length = len(newsletter_content.split())\n",
    "            sections_included = len(drafted_sections)\n",
    "            \n",
    "            # Mock quality score based on content metrics\n",
    "            base_quality = 7.0\n",
    "            if sections_included >= 4: base_quality += 0.5\n",
    "            if newsletter_length >= 2000: base_quality += 0.5\n",
    "            if newsletter_length >= 3000: base_quality += 0.5\n",
    "            final_quality_score = min(10.0, base_quality)\n",
    "            \n",
    "            # Mark workflow as complete\n",
    "            state.current_step = 9\n",
    "            state.workflow_complete = True\n",
    "            \n",
    "            # Also update workflow status for UI\n",
    "            self.workflow_status.complete_step(step_name)\n",
    "\n",
    "            if self.verbose:\n",
    "                print(f\"✅ Completed Step 9: Finalized newsletter ({newsletter_length} words)\")\n",
    "\n",
    "            status_msg = f\"🎉 Step 9 completed successfully! Newsletter finalized with {sections_included} sections and {newsletter_length} words.\"\n",
    "            status_msg += f\"\\n⭐ Quality score: {final_quality_score:.1f}/10\"\n",
    "            status_msg += f\"\\n📰 Complete newsletter stored in persistent state\"\n",
    "            status_msg += f\"\\n✅ Workflow complete! All 9 steps finished successfully.\"\n",
    "            return status_msg\n",
    "\n",
    "        except Exception as e:\n",
    "            self.workflow_status.error_step(step_name, str(e))\n",
    "            return f\"❌ Step 9 failed: {str(e)}\"\n",
    "\n",
    "    def create_tool(self) -> FunctionTool:\n",
    "        \"\"\"Create a FunctionTool instance following OpenAI Agents SDK conventions\"\"\"\n",
    "        return FunctionTool(\n",
    "            name=\"finalize_newsletter\",\n",
    "            description=\"Execute Step 9: Combine all sections into the final newsletter with formatting and polish. Requires Step 8 to be completed first.\",\n",
    "            params_json_schema={\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {},\n",
    "                \"required\": []\n",
    "            },\n",
    "            on_invoke_tool=self._finalize_newsletter\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72dc48f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MockNewsletterAgent(Agent[NewsletterAgentState]):\n",
    "    \"\"\"Mock newsletter agent with persistent state and workflow tools\"\"\"\n",
    "\n",
    "    def __init__(self, session_id: str = \"newsletter_agent\", verbose: bool = False):\n",
    "        \"\"\"\n",
    "        Initialize the MockNewsletterAgent with persistent state\n",
    "\n",
    "        Args:\n",
    "            session_id: Unique identifier for the session (for persistence)\n",
    "            verbose: Enable verbose logging\n",
    "        \"\"\"\n",
    "        # Initialize session for persistence\n",
    "        self.session = SQLiteSession(session_id, \"newsletter_agent.db\")\n",
    "        self.workflow_status = WorkflowStatus()  # Keep for progress tracking UI\n",
    "        self.verbose = verbose\n",
    "\n",
    "        # System prompt that guides tool selection based on workflow status\n",
    "        system_prompt = \"\"\"\n",
    "You are an AI newsletter writing agent that executes a 9-step workflow process using tools with persistent state.\n",
    "\n",
    "WORKFLOW OVERVIEW:\n",
    "1. Step 1: Gather URLs - Collect headlines and URLs from various sources\n",
    "2. Step 2: Filter URLs - Filter headlines to AI-related content only\n",
    "3. Step 3: Download Articles - Fetch full article content from URLs\n",
    "4. Step 4: Extract Summaries - Create bullet point summaries of each article\n",
    "5. Step 5: Cluster By Topic - Group articles by thematic topics\n",
    "6. Step 6: Rate Articles - Evaluate article quality and importance\n",
    "7. Step 7: Select Sections - Organize articles into newsletter sections\n",
    "8. Step 8: Draft Sections - Write content for each section\n",
    "9. Step 9: Finalize Newsletter - Combine sections into final newsletter\n",
    "\n",
    "WORKFLOW RESUME LOGIC:\n",
    "- You maintain persistent state between runs and can resume from any step\n",
    "- ALWAYS start by checking workflow status to understand current progress\n",
    "- If current_step >= 1, you can resume from any completed step forward\n",
    "- Steps are idempotent - if a step is already completed, tools will return cached results\n",
    "- When resuming, automatically continue from the next incomplete step\n",
    "\n",
    "INSTRUCTIONS:\n",
    "- ALWAYS start by checking the current workflow status using check_workflow_status\n",
    "- Use inspect_state tool to examine detailed state data when debugging\n",
    "- Execute workflow steps in the correct order using the appropriate tools\n",
    "- Each step has prerequisites - only execute a step if the previous step is completed\n",
    "- If a user asks to \"run all steps\" or \"create the newsletter\", execute all remaining steps in sequence\n",
    "- If a user asks for a specific step, execute only that step (if prerequisites are met)\n",
    "- If a user asks to \"resume\" or \"continue\", start from the next incomplete step\n",
    "- Always check status between steps to ensure proper sequencing\n",
    "- Your state persists between sessions - you can resume work from where you left off\n",
    "\n",
    "TOOL SELECTION STRATEGY:\n",
    "1. First, always use check_workflow_status to understand current state and progress\n",
    "2. If resuming, identify the next step that needs to be executed\n",
    "3. Use the appropriate tool for that step\n",
    "4. After each step, check status again to confirm progress\n",
    "5. Continue until workflow is complete or user request is fulfilled\n",
    "\n",
    "RESUME EXAMPLES:\n",
    "- If current_step=3, next step is step 4 (Extract Summaries)\n",
    "- If current_step=7, next step is step 8 (Draft Sections)  \n",
    "- If current_step=9, workflow is complete - no further steps needed\n",
    "\n",
    "Remember: Your state is persistent. You can safely resume from any point. Never skip steps or execute them out of order.\n",
    "\"\"\"\n",
    "\n",
    "        # Create all workflow tools\n",
    "        tools = self._create_workflow_tools()\n",
    "\n",
    "        super().__init__(\n",
    "            name=\"MockNewsletterAgent\",\n",
    "            instructions=system_prompt,\n",
    "            model=\"gpt-4o-mini\",\n",
    "            tools=tools\n",
    "        )\n",
    "\n",
    "        # Initialize default state\n",
    "        self.default_state = NewsletterAgentState()\n",
    "\n",
    "        if self.verbose:\n",
    "            print(f\"Initialized MockNewsletterAgent with persistent state and 9-step workflow\")\n",
    "            print(f\"Session ID: {session_id}\")\n",
    "\n",
    "    async def run_step(self, user_input: str) -> str:\n",
    "        \"\"\"Run a workflow step with persistent state\"\"\"\n",
    "        result = await Runner.run(\n",
    "            self,\n",
    "            user_input,\n",
    "            session=self.session,\n",
    "            context=self.default_state,  # Will load from session if exists\n",
    "            max_turns=50  # Increased for complete 9-step workflow\n",
    "        )\n",
    "        return result.final_output\n",
    "\n",
    "    def _create_workflow_tools(self):\n",
    "        \"\"\"Create all workflow tools for the agent\"\"\"\n",
    "        tools = []\n",
    "\n",
    "        # Status checking and inspection tools\n",
    "        workflow_status_tool = WorkflowStatusTool(self.workflow_status)\n",
    "        tools.append(workflow_status_tool.create_tool())\n",
    "        \n",
    "        state_inspection_tool = StateInspectionTool(self.verbose)\n",
    "        tools.append(state_inspection_tool.create_tool())\n",
    "\n",
    "        # Workflow step tools - create FunctionTool instances\n",
    "        gather_tool = GatherUrlsTool(self.workflow_status, self.verbose)\n",
    "        tools.append(gather_tool.create_tool())\n",
    "\n",
    "        filter_tool = FilterUrlsTool(self.workflow_status, self.verbose)\n",
    "        tools.append(filter_tool.create_tool())\n",
    "\n",
    "        download_tool = DownloadArticlesTool(self.workflow_status, self.verbose)\n",
    "        tools.append(download_tool.create_tool())\n",
    "\n",
    "        extract_tool = ExtractSummariesTool(self.workflow_status, self.verbose)\n",
    "        tools.append(extract_tool.create_tool())\n",
    "\n",
    "        cluster_tool = ClusterByTopicTool(self.workflow_status, self.verbose)\n",
    "        tools.append(cluster_tool.create_tool())\n",
    "\n",
    "        rate_tool = RateArticlesTool(self.workflow_status, self.verbose)\n",
    "        tools.append(rate_tool.create_tool())\n",
    "\n",
    "        sections_tool = SelectSectionsTool(self.workflow_status, self.verbose)\n",
    "        tools.append(sections_tool.create_tool())\n",
    "\n",
    "        draft_tool = DraftSectionsTool(self.workflow_status, self.verbose)\n",
    "        tools.append(draft_tool.create_tool())\n",
    "\n",
    "        finalize_tool = FinalizeNewsletterTool(self.workflow_status, self.verbose)\n",
    "        tools.append(finalize_tool.create_tool())\n",
    "\n",
    "        return tools\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a118cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import Agent, Runner, set_default_openai_client, FunctionTool, Tool, SQLiteSession\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a1d1710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized MockNewsletterAgent with persistent state and 9-step workflow\n",
      "Session ID: newsletter_agent\n"
     ]
    }
   ],
   "source": [
    "news_agent = MockNewsletterAgent(verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed3ca518",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:8787/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "ename": "UserError",
     "evalue": "Error running tool check_workflow_status: 'NoneType' object has no attribute 'current_step'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/asdk/lib/python3.11/site-packages/agents/_run_impl.py:559\u001b[39m, in \u001b[36mRunImpl.execute_function_tool_calls.<locals>.run_single_tool\u001b[39m\u001b[34m(func_tool, tool_call)\u001b[39m\n\u001b[32m    558\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m559\u001b[39m     _, _, result = \u001b[38;5;28;01mawait\u001b[39;00m asyncio.gather(\n\u001b[32m    560\u001b[39m         hooks.on_tool_start(tool_context, agent, func_tool),\n\u001b[32m    561\u001b[39m         (\n\u001b[32m    562\u001b[39m             agent.hooks.on_tool_start(tool_context, agent, func_tool)\n\u001b[32m    563\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m agent.hooks\n\u001b[32m    564\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m _coro.noop_coroutine()\n\u001b[32m    565\u001b[39m         ),\n\u001b[32m    566\u001b[39m         func_tool.on_invoke_tool(tool_context, tool_call.arguments),\n\u001b[32m    567\u001b[39m     )\n\u001b[32m    569\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m asyncio.gather(\n\u001b[32m    570\u001b[39m         hooks.on_tool_end(tool_context, agent, func_tool, result),\n\u001b[32m    571\u001b[39m         (\n\u001b[32m   (...)\u001b[39m\u001b[32m    575\u001b[39m         ),\n\u001b[32m    576\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/asdk/lib/python3.11/asyncio/tasks.py:349\u001b[39m, in \u001b[36mTask.__wakeup\u001b[39m\u001b[34m(self, future)\u001b[39m\n\u001b[32m    348\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m349\u001b[39m     \u001b[43mfuture\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    350\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    351\u001b[39m     \u001b[38;5;66;03m# This may also be a cancellation.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/asdk/lib/python3.11/asyncio/tasks.py:277\u001b[39m, in \u001b[36mTask.__step\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m    274\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    275\u001b[39m     \u001b[38;5;66;03m# We use the `send` method directly, because coroutines\u001b[39;00m\n\u001b[32m    276\u001b[39m     \u001b[38;5;66;03m# don't have `__iter__` and `__next__` methods.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m277\u001b[39m     result = coro.send(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    278\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 21\u001b[39m, in \u001b[36mWorkflowStatusTool._check_workflow_status\u001b[39m\u001b[34m(self, ctx, args)\u001b[39m\n\u001b[32m     13\u001b[39m step_names = [\n\u001b[32m     14\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mstep_01_gather_urls\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstep_02_filter_urls\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstep_03_download_articles\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     15\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mstep_04_extract_summaries\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstep_05_cluster_by_topic\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstep_06_rate_articles\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     16\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mstep_07_select_sections\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstep_08_draft_sections\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstep_09_finalize_newsletter\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     17\u001b[39m ]\n\u001b[32m     19\u001b[39m lines = [\n\u001b[32m     20\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mWORKFLOW STATUS (FROM PERSISTENT STATE)\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCurrent Step: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mstate\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcurrent_step\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/9\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     22\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mWorkflow Complete: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstate.workflow_complete\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     23\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mProgress: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(state.current_step/\u001b[32m9\u001b[39m)*\u001b[32m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m%\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     24\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     25\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mStep Details:\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     26\u001b[39m ]\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, step_name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(step_names, \u001b[32m1\u001b[39m):\n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'current_step'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mUserError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m results = \u001b[38;5;28;01mawait\u001b[39;00m Runner.run(news_agent, \n\u001b[32m      2\u001b[39m                            \u001b[33m\"\u001b[39m\u001b[33mRun all the workflow steps in order and create the newsletter\u001b[39m\u001b[33m\"\u001b[39m,  \n\u001b[32m      3\u001b[39m                            max_turns=\u001b[32m100\u001b[39m)\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(results.final_output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/asdk/lib/python3.11/site-packages/agents/run.py:237\u001b[39m, in \u001b[36mRunner.run\u001b[39m\u001b[34m(cls, starting_agent, input, context, max_turns, hooks, run_config, previous_response_id, session)\u001b[39m\n\u001b[32m    210\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Run a workflow starting at the given agent. The agent will run in a loop until a final\u001b[39;00m\n\u001b[32m    211\u001b[39m \u001b[33;03moutput is generated. The loop runs like so:\u001b[39;00m\n\u001b[32m    212\u001b[39m \u001b[33;03m1. The agent is invoked with the given input.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    234\u001b[39m \u001b[33;03m    agent. Agents may perform handoffs, so we don't know the specific type of the output.\u001b[39;00m\n\u001b[32m    235\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    236\u001b[39m runner = DEFAULT_AGENT_RUNNER\n\u001b[32m--> \u001b[39m\u001b[32m237\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m runner.run(\n\u001b[32m    238\u001b[39m     starting_agent,\n\u001b[32m    239\u001b[39m     \u001b[38;5;28minput\u001b[39m,\n\u001b[32m    240\u001b[39m     context=context,\n\u001b[32m    241\u001b[39m     max_turns=max_turns,\n\u001b[32m    242\u001b[39m     hooks=hooks,\n\u001b[32m    243\u001b[39m     run_config=run_config,\n\u001b[32m    244\u001b[39m     previous_response_id=previous_response_id,\n\u001b[32m    245\u001b[39m     session=session,\n\u001b[32m    246\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/asdk/lib/python3.11/site-packages/agents/run.py:443\u001b[39m, in \u001b[36mAgentRunner.run\u001b[39m\u001b[34m(self, starting_agent, input, **kwargs)\u001b[39m\n\u001b[32m    438\u001b[39m logger.debug(\n\u001b[32m    439\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRunning agent \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcurrent_agent.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (turn \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcurrent_turn\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    440\u001b[39m )\n\u001b[32m    442\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m current_turn == \u001b[32m1\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m443\u001b[39m     input_guardrail_results, turn_result = \u001b[38;5;28;01mawait\u001b[39;00m asyncio.gather(\n\u001b[32m    444\u001b[39m         \u001b[38;5;28mself\u001b[39m._run_input_guardrails(\n\u001b[32m    445\u001b[39m             starting_agent,\n\u001b[32m    446\u001b[39m             starting_agent.input_guardrails\n\u001b[32m    447\u001b[39m             + (run_config.input_guardrails \u001b[38;5;129;01mor\u001b[39;00m []),\n\u001b[32m    448\u001b[39m             _copy_str_or_list(prepared_input),\n\u001b[32m    449\u001b[39m             context_wrapper,\n\u001b[32m    450\u001b[39m         ),\n\u001b[32m    451\u001b[39m         \u001b[38;5;28mself\u001b[39m._run_single_turn(\n\u001b[32m    452\u001b[39m             agent=current_agent,\n\u001b[32m    453\u001b[39m             all_tools=all_tools,\n\u001b[32m    454\u001b[39m             original_input=original_input,\n\u001b[32m    455\u001b[39m             generated_items=generated_items,\n\u001b[32m    456\u001b[39m             hooks=hooks,\n\u001b[32m    457\u001b[39m             context_wrapper=context_wrapper,\n\u001b[32m    458\u001b[39m             run_config=run_config,\n\u001b[32m    459\u001b[39m             should_run_agent_start_hooks=should_run_agent_start_hooks,\n\u001b[32m    460\u001b[39m             tool_use_tracker=tool_use_tracker,\n\u001b[32m    461\u001b[39m             previous_response_id=previous_response_id,\n\u001b[32m    462\u001b[39m         ),\n\u001b[32m    463\u001b[39m     )\n\u001b[32m    464\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    465\u001b[39m     turn_result = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._run_single_turn(\n\u001b[32m    466\u001b[39m         agent=current_agent,\n\u001b[32m    467\u001b[39m         all_tools=all_tools,\n\u001b[32m   (...)\u001b[39m\u001b[32m    475\u001b[39m         previous_response_id=previous_response_id,\n\u001b[32m    476\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/asdk/lib/python3.11/asyncio/tasks.py:349\u001b[39m, in \u001b[36mTask.__wakeup\u001b[39m\u001b[34m(self, future)\u001b[39m\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__wakeup\u001b[39m(\u001b[38;5;28mself\u001b[39m, future):\n\u001b[32m    348\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m349\u001b[39m         \u001b[43mfuture\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    350\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    351\u001b[39m         \u001b[38;5;66;03m# This may also be a cancellation.\u001b[39;00m\n\u001b[32m    352\u001b[39m         \u001b[38;5;28mself\u001b[39m.__step(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/asdk/lib/python3.11/asyncio/tasks.py:279\u001b[39m, in \u001b[36mTask.__step\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m    277\u001b[39m         result = coro.send(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    278\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m279\u001b[39m         result = coro.throw(exc)\n\u001b[32m    280\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    281\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._must_cancel:\n\u001b[32m    282\u001b[39m         \u001b[38;5;66;03m# Task is cancelled right before coro stops.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/asdk/lib/python3.11/site-packages/agents/run.py:1061\u001b[39m, in \u001b[36mAgentRunner._run_single_turn\u001b[39m\u001b[34m(cls, agent, all_tools, original_input, generated_items, hooks, context_wrapper, run_config, should_run_agent_start_hooks, tool_use_tracker, previous_response_id)\u001b[39m\n\u001b[32m   1045\u001b[39m \u001b[38;5;28minput\u001b[39m.extend([generated_item.to_input_item() \u001b[38;5;28;01mfor\u001b[39;00m generated_item \u001b[38;5;129;01min\u001b[39;00m generated_items])\n\u001b[32m   1047\u001b[39m new_response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mcls\u001b[39m._get_new_response(\n\u001b[32m   1048\u001b[39m     agent,\n\u001b[32m   1049\u001b[39m     system_prompt,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1058\u001b[39m     prompt_config,\n\u001b[32m   1059\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1061\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mcls\u001b[39m._get_single_step_result_from_response(\n\u001b[32m   1062\u001b[39m     agent=agent,\n\u001b[32m   1063\u001b[39m     original_input=original_input,\n\u001b[32m   1064\u001b[39m     pre_step_items=generated_items,\n\u001b[32m   1065\u001b[39m     new_response=new_response,\n\u001b[32m   1066\u001b[39m     output_schema=output_schema,\n\u001b[32m   1067\u001b[39m     all_tools=all_tools,\n\u001b[32m   1068\u001b[39m     handoffs=handoffs,\n\u001b[32m   1069\u001b[39m     hooks=hooks,\n\u001b[32m   1070\u001b[39m     context_wrapper=context_wrapper,\n\u001b[32m   1071\u001b[39m     run_config=run_config,\n\u001b[32m   1072\u001b[39m     tool_use_tracker=tool_use_tracker,\n\u001b[32m   1073\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/asdk/lib/python3.11/site-packages/agents/run.py:1101\u001b[39m, in \u001b[36mAgentRunner._get_single_step_result_from_response\u001b[39m\u001b[34m(cls, agent, all_tools, original_input, pre_step_items, new_response, output_schema, handoffs, hooks, context_wrapper, run_config, tool_use_tracker)\u001b[39m\n\u001b[32m   1091\u001b[39m processed_response = RunImpl.process_model_response(\n\u001b[32m   1092\u001b[39m     agent=agent,\n\u001b[32m   1093\u001b[39m     all_tools=all_tools,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1096\u001b[39m     handoffs=handoffs,\n\u001b[32m   1097\u001b[39m )\n\u001b[32m   1099\u001b[39m tool_use_tracker.add_tool_use(agent, processed_response.tools_used)\n\u001b[32m-> \u001b[39m\u001b[32m1101\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m RunImpl.execute_tools_and_side_effects(\n\u001b[32m   1102\u001b[39m     agent=agent,\n\u001b[32m   1103\u001b[39m     original_input=original_input,\n\u001b[32m   1104\u001b[39m     pre_step_items=pre_step_items,\n\u001b[32m   1105\u001b[39m     new_response=new_response,\n\u001b[32m   1106\u001b[39m     processed_response=processed_response,\n\u001b[32m   1107\u001b[39m     output_schema=output_schema,\n\u001b[32m   1108\u001b[39m     hooks=hooks,\n\u001b[32m   1109\u001b[39m     context_wrapper=context_wrapper,\n\u001b[32m   1110\u001b[39m     run_config=run_config,\n\u001b[32m   1111\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/asdk/lib/python3.11/site-packages/agents/_run_impl.py:253\u001b[39m, in \u001b[36mRunImpl.execute_tools_and_side_effects\u001b[39m\u001b[34m(cls, agent, original_input, pre_step_items, new_response, processed_response, output_schema, hooks, context_wrapper, run_config)\u001b[39m\n\u001b[32m    250\u001b[39m new_step_items.extend(processed_response.new_items)\n\u001b[32m    252\u001b[39m \u001b[38;5;66;03m# First, lets run the tool calls - function tools and computer actions\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m253\u001b[39m function_results, computer_results = \u001b[38;5;28;01mawait\u001b[39;00m asyncio.gather(\n\u001b[32m    254\u001b[39m     \u001b[38;5;28mcls\u001b[39m.execute_function_tool_calls(\n\u001b[32m    255\u001b[39m         agent=agent,\n\u001b[32m    256\u001b[39m         tool_runs=processed_response.functions,\n\u001b[32m    257\u001b[39m         hooks=hooks,\n\u001b[32m    258\u001b[39m         context_wrapper=context_wrapper,\n\u001b[32m    259\u001b[39m         config=run_config,\n\u001b[32m    260\u001b[39m     ),\n\u001b[32m    261\u001b[39m     \u001b[38;5;28mcls\u001b[39m.execute_computer_actions(\n\u001b[32m    262\u001b[39m         agent=agent,\n\u001b[32m    263\u001b[39m         actions=processed_response.computer_actions,\n\u001b[32m    264\u001b[39m         hooks=hooks,\n\u001b[32m    265\u001b[39m         context_wrapper=context_wrapper,\n\u001b[32m    266\u001b[39m         config=run_config,\n\u001b[32m    267\u001b[39m     ),\n\u001b[32m    268\u001b[39m )\n\u001b[32m    269\u001b[39m new_step_items.extend([result.run_item \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m function_results])\n\u001b[32m    270\u001b[39m new_step_items.extend(computer_results)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/asdk/lib/python3.11/asyncio/tasks.py:349\u001b[39m, in \u001b[36mTask.__wakeup\u001b[39m\u001b[34m(self, future)\u001b[39m\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__wakeup\u001b[39m(\u001b[38;5;28mself\u001b[39m, future):\n\u001b[32m    348\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m349\u001b[39m         \u001b[43mfuture\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    350\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    351\u001b[39m         \u001b[38;5;66;03m# This may also be a cancellation.\u001b[39;00m\n\u001b[32m    352\u001b[39m         \u001b[38;5;28mself\u001b[39m.__step(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/asdk/lib/python3.11/asyncio/tasks.py:279\u001b[39m, in \u001b[36mTask.__step\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m    277\u001b[39m         result = coro.send(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    278\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m279\u001b[39m         result = coro.throw(exc)\n\u001b[32m    280\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    281\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._must_cancel:\n\u001b[32m    282\u001b[39m         \u001b[38;5;66;03m# Task is cancelled right before coro stops.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/asdk/lib/python3.11/site-packages/agents/_run_impl.py:597\u001b[39m, in \u001b[36mRunImpl.execute_function_tool_calls\u001b[39m\u001b[34m(cls, agent, tool_runs, hooks, context_wrapper, config)\u001b[39m\n\u001b[32m    594\u001b[39m     function_tool = tool_run.function_tool\n\u001b[32m    595\u001b[39m     tasks.append(run_single_tool(function_tool, tool_run.tool_call))\n\u001b[32m--> \u001b[39m\u001b[32m597\u001b[39m results = \u001b[38;5;28;01mawait\u001b[39;00m asyncio.gather(*tasks)\n\u001b[32m    599\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[32m    600\u001b[39m     FunctionToolResult(\n\u001b[32m    601\u001b[39m         tool=tool_run.function_tool,\n\u001b[32m   (...)\u001b[39m\u001b[32m    609\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m tool_run, result \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(tool_runs, results)\n\u001b[32m    610\u001b[39m ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/asdk/lib/python3.11/asyncio/tasks.py:349\u001b[39m, in \u001b[36mTask.__wakeup\u001b[39m\u001b[34m(self, future)\u001b[39m\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__wakeup\u001b[39m(\u001b[38;5;28mself\u001b[39m, future):\n\u001b[32m    348\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m349\u001b[39m         \u001b[43mfuture\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    350\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    351\u001b[39m         \u001b[38;5;66;03m# This may also be a cancellation.\u001b[39;00m\n\u001b[32m    352\u001b[39m         \u001b[38;5;28mself\u001b[39m.__step(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/asdk/lib/python3.11/asyncio/tasks.py:279\u001b[39m, in \u001b[36mTask.__step\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m    277\u001b[39m         result = coro.send(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    278\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m279\u001b[39m         result = coro.throw(exc)\n\u001b[32m    280\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    281\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._must_cancel:\n\u001b[32m    282\u001b[39m         \u001b[38;5;66;03m# Task is cancelled right before coro stops.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/asdk/lib/python3.11/site-packages/agents/_run_impl.py:586\u001b[39m, in \u001b[36mRunImpl.execute_function_tool_calls.<locals>.run_single_tool\u001b[39m\u001b[34m(func_tool, tool_call)\u001b[39m\n\u001b[32m    584\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, AgentsException):\n\u001b[32m    585\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m--> \u001b[39m\u001b[32m586\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m UserError(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mError running tool \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc_tool.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    588\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m config.trace_include_sensitive_data:\n\u001b[32m    589\u001b[39m     span_fn.span_data.output = result\n",
      "\u001b[31mUserError\u001b[39m: Error running tool check_workflow_status: 'NoneType' object has no attribute 'current_step'"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/traces/ingest \"HTTP/1.1 204 No Content\"\n"
     ]
    }
   ],
   "source": [
    "results = await Runner.run(news_agent, \n",
    "                           \"Run all the workflow steps in order and create the newsletter\",  \n",
    "                           max_turns=100)\n",
    "print(results.final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44caf2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# review slides\n",
    "\n",
    "# review workflow status, move to a module\n",
    "# all prints should be logs\n",
    "# section writing and composition will have the critic /optimizer loop\n",
    "# add batch with async\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda8255a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e085a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WorkflowStatus:\n",
    "    \"\"\"Tracks status of a multi-step workflow.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "            \"\"\"Initialize workflow status with predefined steps.\"\"\"\n",
    "            self.steps: Dict[str, StepInfo] = {\n",
    "                \"1. URL Gathering\": StepInfo(),\n",
    "                \"2. URL Filtering\": StepInfo(),\n",
    "                \"3. Article Fetching\": StepInfo(),\n",
    "                \"4. Article Summarizing\": StepInfo(),\n",
    "                \"5. Topic Clustering\": StepInfo(),\n",
    "                \"6. Article Rating\": StepInfo(),\n",
    "                \"7. Section Selection\": StepInfo(),\n",
    "                \"8. Section Writing\": StepInfo(),\n",
    "                \"9. Newsletter Composition\": StepInfo(),\n",
    "            }\n",
    "            self.workflow_start_time = datetime.now()\n",
    "\n",
    "    def start_step(self, step_name: str, details: Optional[str] = None) -> None:\n",
    "        \"\"\"\n",
    "        Mark a step as started.\n",
    "\n",
    "          Args:\n",
    "              step_name: Name of the step (e.g., \"1. Scraping\")\n",
    "              details: Optional details about what's being processed\n",
    "        \"\"\"\n",
    "\n",
    "        if step_name not in self.steps:\n",
    "            raise ValueError(f\"Unknown step: {step_name}\")\n",
    "\n",
    "        step = self.steps[step_name]\n",
    "        step.status = StepStatus.STARTED\n",
    "        step.start_time = datetime.now()\n",
    "        step.details = details\n",
    "        step.error_message = None  # Clear any previous errors\n",
    "        print(f\"🚀 Started: {step_name}\" + (f\" - {details}\" if details else \"\"))\n",
    "\n",
    "    def complete_step(self, step_name: str, details: Optional[str] = None) -> None:\n",
    "        \"\"\"\n",
    "        Mark a step as complete.\n",
    "\n",
    "        Args:\n",
    "              step_name: Name of the step\n",
    "              details: Optional completion details\n",
    "        \"\"\"\n",
    "        if step_name not in self.steps:\n",
    "            raise ValueError(f\"Unknown step: {step_name}\")\n",
    "\n",
    "        step = self.steps[step_name]\n",
    "        step.status = StepStatus.COMPLETE\n",
    "        step.end_time = datetime.now()\n",
    "        if details:\n",
    "            step.details = details\n",
    "\n",
    "        duration_str = f\"({step.duration:.1f}s)\" if step.duration else \"\"\n",
    "        print(f\"✅ Completed: {step_name}{duration_str}\" + (f\" - {details}\" if details else \"\"))\n",
    "\n",
    "    def error_step(self, step_name: str, error_message: str) -> None:\n",
    "        \"\"\"\n",
    "        Mark a step as having an error.\n",
    "\n",
    "        Args:\n",
    "            step_name: Name of the step\n",
    "            error_message: Description of the error\n",
    "        \"\"\"\n",
    "        if step_name not in self.steps:\n",
    "            raise ValueError(f\"Unknown step: {step_name}\")\n",
    "\n",
    "        step = self.steps[step_name]\n",
    "        step.status = StepStatus.ERROR\n",
    "        step.end_time = datetime.now()\n",
    "        step.error_message = error_message\n",
    "\n",
    "        duration_str = f\" (after {step.duration:.1f}s)\" if step.duration else \"\"\n",
    "        print(f\"❌ Error in: {step_name}{duration_str} - {error_message}\")\n",
    "\n",
    "\n",
    "    def get_step_status(self, step_name: str) -> StepStatus:\n",
    "        \"\"\"Get the status of a specific step.\"\"\"\n",
    "        if step_name not in self.steps:\n",
    "            raise ValueError(f\"Unknown step: {step_name}\")\n",
    "        return self.steps[step_name].status\n",
    "\n",
    "    def is_step_complete(self, step_name: str) -> bool:\n",
    "        \"\"\"Check if a specific step is complete.\"\"\"\n",
    "        return self.get_step_status(step_name) == StepStatus.COMPLETE\n",
    "\n",
    "    def get_completed_steps(self) -> list[str]:\n",
    "        \"\"\"Get list of completed step names.\"\"\"\n",
    "        return [name for name, step in self.steps.items() if step.is_complete]\n",
    "\n",
    "    def get_failed_steps(self) -> list[str]:\n",
    "        \"\"\"Get list of failed step names.\"\"\"\n",
    "        return [name for name, step in self.steps.items() if step.has_error]\n",
    "\n",
    "    def get_progress_percentage(self) -> float:\n",
    "        \"\"\"Get workflow completion percentage.\"\"\"\n",
    "        total_steps = len(self.steps)\n",
    "        completed_steps = len(self.get_completed_steps())\n",
    "        return (completed_steps / total_steps) * 100 if total_steps > 0 else 0\n",
    "\n",
    "    def print_status(self) -> None:\n",
    "        \"\"\"Print a formatted status summary.\"\"\"\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"📊 WORKFLOW STATUS\")\n",
    "        print(\"=\"*60)\n",
    "\n",
    "        # Overall progress\n",
    "        progress = self.get_progress_percentage()\n",
    "        completed = len(self.get_completed_steps())\n",
    "        total = len(self.steps)\n",
    "        failed = len(self.get_failed_steps())\n",
    "\n",
    "        print(f\"📈 Progress: {progress:.1f}% ({completed}/{total} complete)\")\n",
    "        if failed > 0:\n",
    "            print(f\"❌ Failed: {failed} steps\")\n",
    "\n",
    "        # Individual step status\n",
    "        print(\"\\n📋 Step Details:\")\n",
    "        for step_name, step_info in self.steps.items():\n",
    "            status_icon = {\n",
    "                StepStatus.NOT_STARTED: \"⭕\",\n",
    "                StepStatus.STARTED: \"🔄\",\n",
    "                StepStatus.COMPLETE: \"✅\",\n",
    "                StepStatus.ERROR: \"❌\"\n",
    "            }[step_info.status]\n",
    "\n",
    "        duration_str = \"\"\n",
    "        if step_info.duration:\n",
    "            duration_str = f\" ({step_info.duration:.1f}s)\"\n",
    "\n",
    "        details_str = \"\"\n",
    "        if step_info.details:\n",
    "            details_str = f\" - {step_info.details}\"\n",
    "        elif step_info.error_message:\n",
    "            details_str = f\" - {step_info.error_message}\"\n",
    "\n",
    "        print(f\"  {status_icon} {step_name}{duration_str}{details_str}\")\n",
    "\n",
    "        # Workflow timing\n",
    "        total_duration = (datetime.now() - self.workflow_start_time).total_seconds()\n",
    "        print(f\"\\n⏱️  Total workflow time: {total_duration:.1f}s\")\n",
    "        print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "    def get_status_dict(self) -> Dict[str, Dict[str, any]]:\n",
    "        \"\"\"Get status as a dictionary for serialization.\"\"\"\n",
    "        return {\n",
    "            step_name: {\n",
    "                \"status\": step_info.status.value,\n",
    "                \"start_time\": step_info.start_time.isoformat() if step_info.start_time else None,\n",
    "                \"end_time\": step_info.end_time.isoformat() if step_info.end_time else None,\n",
    "                \"duration\": step_info.duration,\n",
    "                \"error_message\": step_info.error_message,\n",
    "                \"details\": step_info.details\n",
    "            }\n",
    "            for step_name, step_info in self.steps.items()\n",
    "        }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4ffa70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create workflow status\n",
    "status = WorkflowStatus()\n",
    "\n",
    "# Simulate workflow execution\n",
    "\n",
    "# Start first step\n",
    "status.start_step(\"1. Scraping\", \"Processing 15 RSS feeds\")\n",
    "time.sleep(1)  # Simulate work\n",
    "status.complete_step(\"1. Scraping\", \"Collected 250 headlines\")\n",
    "\n",
    "# Start second step\n",
    "status.start_step(\"2. AI Filtering\", \"Classifying headlines\")\n",
    "time.sleep(0.5)  # Simulate work\n",
    "status.complete_step(\"2. AI Filtering\", \"Filtered to 87 AI-related headlines\")\n",
    "\n",
    "# Simulate an error\n",
    "status.start_step(\"3. Text Fetching\", \"Downloading article content\")\n",
    "time.sleep(0.3)\n",
    "status.error_step(\"3. Text Fetching\", \"Connection timeout after 30s\")\n",
    "\n",
    "# Print status\n",
    "status.print_status()\n",
    "\n",
    "# Check specific conditions\n",
    "if status.is_step_complete(\"1. Scraping\"):\n",
    "    print(\"✅ Ready to proceed with AI filtering results\")\n",
    "\n",
    "if status.get_failed_steps():\n",
    "    print(f\"⚠️  Need to retry: {', '.join(status.get_failed_steps())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fed7b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_news_dataframe():\n",
    "    \"\"\"\n",
    "    Creates an empty DataFrame to support headline/article analysis\n",
    "    - URLs, source tracking and metadata\n",
    "    - Topic classification and clustering\n",
    "    - Content quality ratings and rankings\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Empty DataFrame with predefined column structure\n",
    "    \"\"\"\n",
    "\n",
    "    # column structure\n",
    "    column_dict = {\n",
    "        # Core identifiers and source info\n",
    "        'article_id': 'object',              # Unique identifier for each article\n",
    "        'source':     'object',              # Source category\n",
    "        'headline_title': 'object',          # Article headline/title\n",
    "        'original_url': 'object',            # Initial URL before redirects\n",
    "        'final_url': 'object',               # URL after following redirects\n",
    "        'domain_name': 'category',           # Website domain\n",
    "        'site_name': 'category',             # Human-readable site name\n",
    "        'site_reputation_score': 'float32',  # Reputation/trustworthiness score for the site\n",
    "        'keep_flag': 'boolean',\n",
    "\n",
    "        # File paths and storage\n",
    "        'html_file_path': 'object',          # Path to stored HTML content\n",
    "        'text_file_path': 'object',          # Path to extracted text content\n",
    "\n",
    "        # Time information\n",
    "        'last_updated_timestamp': 'datetime64[ns]',  # When article was last updated\n",
    "        'article_age_days': 'int32',         # Age of article in days\n",
    "        'recency_score': 'float32',          # Calculated recency score (higher = more recent)\n",
    "\n",
    "        # Content analysis\n",
    "        'content_summary': 'object',         # Generated summary of article content\n",
    "        'bullet_points': 'object',           # Key points extracted as bullets\n",
    "        'article_length_chars': 'int32',     # Character count of article content\n",
    "\n",
    "        # Rating flags (LLM-generated probabilities)\n",
    "        'is_high_quality': 'float32',        # LLM probability for low-quality content\n",
    "        'is_off_topic': 'float32',           # LLM probability for off-topic content\n",
    "        'is_low_importance': 'float32',      # 1-LLM probability for high-importance content\n",
    "\n",
    "        # Other ratings\n",
    "        'bradley_terry_score': 'float32',    # Bradley-Terry rating from pairwise article comparisons\n",
    "        'bradley_terry_rank': 'int32',       # Ordinal rank based on Bradley-Terry scores (1 = highest rated)\n",
    "        'adjusted_length_score': 'float32',  # Length-adjusted quality score\n",
    "        'final_composite_rating': 'float32', # Final weighted rating combining multiple factors\n",
    "\n",
    "        # Topic classification\n",
    "        'topic_string': 'object',            # Topic labels as comma-separated string\n",
    "        'topic_list': 'object',              # Topic labels as list/array structure (same topics, different format)\n",
    "\n",
    "        # Organization and clustering (HDBSCAN-based)\n",
    "        'display_order': 'int32',            # Order for display/presentation\n",
    "        'cluster_id': 'int32',               # HDBSCAN cluster identifier (-1 = noise/outlier)\n",
    "        'cluster_label': 'category'          # Human-readable cluster name/description\n",
    "    }\n",
    "\n",
    "    # Create empty DataFrame from column dictionary\n",
    "    df = pd.DataFrame(columns=list(column_dict.keys())).astype(column_dict)\n",
    "\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a22a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class NewsletterState:\n",
    "    \"\"\"\n",
    "    Maintains session state for the OpenAI Agents SDK workflow.\n",
    "\n",
    "    Attributes:\n",
    "        headline_df: DataFrame containing headline data for processing\n",
    "        sources_file: Path to YAML file containing source configurations\n",
    "        sources: Dictionary of source configurations loaded from YAML\n",
    "        cluster_topics: List of clean topic names for headline categorization\n",
    "        max_edits: Maximum number of critic optimizer editing iterations allowed\n",
    "        edit_complete: Boolean flag indicating if editing process is finished\n",
    "        n_browsers: Number of concurrent Playwright browser instances for downloads\n",
    "    \"\"\"\n",
    "\n",
    "    status: WorkflowStatus = WorkflowStatus()\n",
    "    headline_df: pd.DataFrame = field(default_factory=create_news_dataframe)\n",
    "    sources_file: str = field(default=\"sources.yaml\")\n",
    "    sources: Dict[str, Any] = field(default_factory=dict)\n",
    "    cluster_topics: List[str] = field(default_factory=list)\n",
    "    max_edits: int = field(default=3)\n",
    "    edit_complete: bool = field(default=False)\n",
    "    n_browsers: int = field(default=8)\n",
    "    verbose: bool = field(default=True)\n",
    "\n",
    "\n",
    "    def __post_init__(self):\n",
    "        \"\"\"\n",
    "        Post-initialization validation and setup.\n",
    "\n",
    "        Validates that the configuration makes sense and performs\n",
    "        any necessary initialization steps.\n",
    "        \"\"\"\n",
    "        # Validate max_edits is reasonable\n",
    "        if self.max_edits < 1 or self.max_edits > 10:\n",
    "            raise ValueError(f\"max_edits should be between 1-10, got {self.max_edits}\")\n",
    "\n",
    "        # Validate n_browsers is reasonable\n",
    "        if self.n_browsers < 1 or self.n_browsers > 32:\n",
    "            raise ValueError(f\"n_browsers should be between 1-32, got {self.n_browsers}\")\n",
    "\n",
    "        # Validate sources_file exists and load sources from file automatically\n",
    "        try:\n",
    "            sources_path = Path(self.sources_file)\n",
    "            with open(sources_path, 'r', encoding='utf-8') as file:\n",
    "                self.sources = yaml.safe_load(file) or {}\n",
    "            if self.verbose:\n",
    "                print(f\"Loaded {len(self.sources)} sources from {self.sources_file}\")\n",
    "        except FileNotFoundError:\n",
    "            raise FileNotFoundError(f\"Sources file not found: {self.sources_file}\")\n",
    "        except yaml.YAMLError as e:\n",
    "            raise ValueError(f\"Error parsing YAML file {self.sources_file}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2320126c",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = NewsletterState()\n",
    "state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f89016b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import Agent, Runner, SQLiteSession, function_tool, RunContextWrapper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c475f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsletterAgent(Agent[NewsletterState]):\n",
    "    \"\"\"AI newsletter writing agent with structured workflow\"\"\"\n",
    "\n",
    "    def __init__(self, session_id: str = \"newsletter_agent\"):\n",
    "        self.session = SQLiteSession(session_id, \"newsletter.db\")\n",
    "        self.state = NewsletterState()\n",
    "\n",
    "        super().__init__(\n",
    "            name=\"AINewsletterAgent\",\n",
    "            instructions=\"\"\"\n",
    "            You are an AI newsletter writing agent. Your role is to:\n",
    "            1. Scrape headlines and URLs from various sources\n",
    "            2. Filter the headlines to ones that are about AI\n",
    "            3. Fetch the URLs and save them as plain text\n",
    "            4. Summarize each article to 3 bullet points containing the key facts\n",
    "            5. Extract topics from each article and cluster articles by topic\n",
    "            6. Rate each article according to the provided rubric\n",
    "            7. Identify 6-15 thematic sections + \"Other News\", assign articles to sections and deduplicate\n",
    "            8. Write each section\n",
    "            9. Combine sections and polish\n",
    "\n",
    "            Use the tools available to accomplish these tasks in order.\n",
    "            Always maintain context about workflow progress and data.\n",
    "            Guide users through the workflow steps systematically.\n",
    "            \"\"\",\n",
    "            tools=[\n",
    "                self.step1_scrape_headlines,\n",
    "                self.step2_filter_ai_headlines,\n",
    "                self.step3_fetch_article_texts,\n",
    "                self.step4_summarize_articles,\n",
    "                self.step5_extract_and_cluster_topics,\n",
    "                self.step6_rate_articles,\n",
    "                self.step7_organize_sections,\n",
    "                self.step8_write_sections,\n",
    "                self.step9_finalize_newsletter,\n",
    "                self.get_workflow_status,\n",
    "                self.run_complete_workflow,\n",
    "                self.reset_workflow\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    @function_tool\n",
    "    async def step1_scrape_headlines(\n",
    "        self,\n",
    "        wrapper: RunContextWrapper[NewsletterState],\n",
    "        sources: List[str] = None,\n",
    "        max_articles_per_source: int = 50\n",
    "    ) -> str:\n",
    "        \"\"\"Step 1: Scrape headlines and URLs from various sources\"\"\"\n",
    "        if sources is None:\n",
    "            sources = [\"techcrunch\", \"arstechnica\", \"theverge\", \"wired\", \"venturebeat\"]\n",
    "\n",
    "        scraped_data = []\n",
    "\n",
    "        # Mock scraping implementation (replace with real RSS/API scraping)\n",
    "        for source in sources:\n",
    "            for i in range(max_articles_per_source):\n",
    "                article = {\n",
    "                    'title': f\"{source} AI Article {i+1}: Latest developments in machine learning\",\n",
    "                    'url': f\"https://{source}.com/ai-article-{i+1}\",\n",
    "                    'source': source,\n",
    "                    'published_at': (datetime.now() - timedelta(hours=i)).isoformat(),\n",
    "                    'description': f\"AI-related content from {source}\"\n",
    "                }\n",
    "                scraped_data.append(article)\n",
    "\n",
    "        wrapper.context.raw_headlines = scraped_data\n",
    "        wrapper.context.scraped_urls = [article['url'] for article in scraped_data]\n",
    "        wrapper.context.current_step = 1\n",
    "\n",
    "        return f\"✅ Step 1 Complete: Scraped {len(scraped_data)} headlines from {len(sources)} sources\"\n",
    "\n",
    "\n",
    "    @function_tool\n",
    "    async def step2_filter_ai_content(\n",
    "        self,\n",
    "        wrapper: RunContextWrapper[NewsletterState],\n",
    "        ai_keywords: List[str] = None\n",
    "    ) -> str:\n",
    "        \"\"\"Step 2: Filter headlines to AI-related content only\"\"\"\n",
    "        if not wrapper.context.raw_headlines:\n",
    "            return \"❌ No headlines to filter. Run step 1 first.\"\n",
    "\n",
    "        if ai_keywords is None:\n",
    "            ai_keywords = [\n",
    "                'ai', 'artificial intelligence', 'machine learning', 'deep learning',\n",
    "                'neural network', 'llm', 'gpt', 'transformer', 'chatbot', 'automation',\n",
    "                'computer vision', 'nlp', 'natural language', 'algorithm', 'model'\n",
    "            ]\n",
    "\n",
    "        ai_articles = []\n",
    "        for article in wrapper.context.raw_headlines:\n",
    "            title_lower = article['title'].lower()\n",
    "            desc_lower = article['description'].lower()\n",
    "\n",
    "            # Check if any AI keywords are present\n",
    "            if any(keyword in title_lower or keyword in desc_lower for keyword in ai_keywords):\n",
    "                ai_articles.append(article)\n",
    "\n",
    "        wrapper.context.ai_headlines = pd.DataFrame(ai_articles)\n",
    "        wrapper.context.current_step = 2\n",
    "\n",
    "        return f\"✅ Step 2 Complete: Filtered to {len(ai_articles)} AI-related headlines from {len(wrapper.context.raw_headlines)} total\"\n",
    "\n",
    "    @function_tool\n",
    "    async def step3_fetch_article_texts(\n",
    "        self,\n",
    "        wrapper: RunContextWrapper[NewsletterState]\n",
    "    ) -> str:\n",
    "        \"\"\"Step 3: Fetch full article texts from URLs\"\"\"\n",
    "        if wrapper.context.ai_headlines.empty:\n",
    "            return \"❌ No AI headlines to fetch. Complete steps 1-2 first.\"\n",
    "\n",
    "        # Mock article fetching (replace with actual web scraping)\n",
    "        article_texts = {}\n",
    "\n",
    "        for _, row in wrapper.context.ai_headlines.iterrows():\n",
    "            url = row['url']\n",
    "            # Mock article content\n",
    "            article_texts[url] = f\"\"\"\n",
    "            {row['title']}\n",
    "\n",
    "            This is a mock article about AI developments. In a real implementation,\n",
    "            you would use libraries like requests + BeautifulSoup or newspaper3k\n",
    "            to extract the full article text from the URL.\n",
    "\n",
    "            Key points about this AI story:\n",
    "            - Advancement in machine learning techniques\n",
    "            - Impact on industry applications\n",
    "            - Future implications for AI development\n",
    "\n",
    "            This content would be much longer in practice, containing the full\n",
    "            article text that needs to be summarized and analyzed.\n",
    "            \"\"\"\n",
    "\n",
    "        wrapper.context.article_texts = article_texts\n",
    "        wrapper.context.current_step = 3\n",
    "\n",
    "        return f\"✅ Step 3 Complete: Fetched full text for {len(article_texts)} articles\"\n",
    "\n",
    "    @function_tool\n",
    "    async def step4_summarize_articles(\n",
    "        self,\n",
    "        wrapper: RunContextWrapper[NewsletterState]\n",
    "    ) -> str:\n",
    "        \"\"\"Step 4: Summarize each article to 3 key bullet points\"\"\"\n",
    "        if not wrapper.context.article_texts:\n",
    "            return \"❌ No article texts to summarize. Complete steps 1-3 first.\"\n",
    "\n",
    "        summaries = {}\n",
    "\n",
    "        for url, text in wrapper.context.article_texts.items():\n",
    "            # Mock summarization (replace with actual LLM summarization)\n",
    "            summaries[url] = [\n",
    "                \"• Key development in AI technology or research\",\n",
    "                \"• Practical implications for businesses or developers\",\n",
    "                \"• Future outlook or next steps in this area\"\n",
    "            ]\n",
    "\n",
    "        wrapper.context.article_summaries = summaries\n",
    "        wrapper.context.current_step = 4\n",
    "\n",
    "        return f\"✅ Step 4 Complete: Generated 3-point summaries for {len(summaries)} articles\"\n",
    "\n",
    "    @function_tool\n",
    "    async def step5_extract_and_cluster_topics(\n",
    "        self,\n",
    "        wrapper: RunContextWrapper[NewsletterState],\n",
    "        max_clusters: int = 8\n",
    "    ) -> str:\n",
    "        \"\"\"Step 5: Extract topics and cluster articles\"\"\"\n",
    "        if not wrapper.context.article_texts:\n",
    "            return \"❌ No articles to analyze. Complete steps 1-4 first.\"\n",
    "\n",
    "        # Extract topics from each article (mock implementation)\n",
    "        article_topics = {}\n",
    "        all_topics = []\n",
    "\n",
    "        for url, text in wrapper.context.article_texts.items():\n",
    "            # Mock topic extraction (replace with NLP)\n",
    "            topics = ['machine learning', 'business applications', 'research', 'ethics']\n",
    "            article_topics[url] = topics\n",
    "            all_topics.extend(topics)\n",
    "\n",
    "        # Cluster articles by common topics\n",
    "        topic_counts = Counter(all_topics)\n",
    "        main_topics = [topic for topic, count in topic_counts.most_common(max_clusters)]\n",
    "\n",
    "        topic_clusters = {}\n",
    "        for topic in main_topics:\n",
    "            topic_clusters[topic] = [\n",
    "                url for url, topics in article_topics.items()\n",
    "                if topic in topics\n",
    "            ]\n",
    "\n",
    "        wrapper.context.article_topics = article_topics\n",
    "        wrapper.context.topic_clusters = topic_clusters\n",
    "        wrapper.context.current_step = 5\n",
    "\n",
    "        return f\"✅ Step 5 Complete: Extracted topics and created {len(topic_clusters)} clusters\"\n",
    "\n",
    "    @function_tool\n",
    "    async def step6_rate_articles(\n",
    "        self,\n",
    "        wrapper: RunContextWrapper[NewsletterState],\n",
    "        custom_rubric: Dict[str, str] = None\n",
    "    ) -> str:\n",
    "        \"\"\"Step 6: Rate articles according to rubric\"\"\"\n",
    "        if not wrapper.context.article_texts:\n",
    "            return \"❌ No articles to rate. Complete previous steps first.\"\n",
    "\n",
    "        if custom_rubric:\n",
    "            wrapper.context.rating_rubric.update(custom_rubric)\n",
    "\n",
    "        # Mock rating (replace with actual evaluation)\n",
    "        ratings = {}\n",
    "        for url in wrapper.context.article_texts.keys():\n",
    "            # Mock scoring based on rubric criteria\n",
    "            relevance_score = 0.8\n",
    "            novelty_score = 0.7\n",
    "            impact_score = 0.9\n",
    "            credibility_score = 0.8\n",
    "\n",
    "            overall_rating = (relevance_score + novelty_score + impact_score + credibility_score) / 4\n",
    "            ratings[url] = overall_rating\n",
    "\n",
    "        wrapper.context.article_ratings = ratings\n",
    "        wrapper.context.current_step = 6\n",
    "\n",
    "        avg_rating = sum(ratings.values()) / len(ratings)\n",
    "        return f\"✅ Step 6 Complete: Rated {len(ratings)} articles. Average rating: {avg_rating:.2f}\"\n",
    "\n",
    "    @function_tool\n",
    "    async def step7_organize_sections(\n",
    "        self,\n",
    "        wrapper: RunContextWrapper[NewsletterState],\n",
    "        target_sections: int = 10\n",
    "    ) -> str:\n",
    "        \"\"\"Step 7: Organize articles into thematic sections\"\"\"\n",
    "        if not wrapper.context.topic_clusters:\n",
    "            return \"❌ No topic clusters available. Complete steps 1-6 first.\"\n",
    "\n",
    "        # Create thematic sections based on clusters and ratings\n",
    "        sections = {}\n",
    "\n",
    "        # Main thematic sections from top clusters\n",
    "        top_clusters = sorted(\n",
    "            wrapper.context.topic_clusters.items(),\n",
    "            key=lambda x: len(x[1]),  # Sort by cluster size\n",
    "            reverse=True\n",
    "        )[:target_sections-1]  # Reserve space for \"Other News\"\n",
    "\n",
    "        for topic, urls in top_clusters:\n",
    "            # Only include high-rated articles\n",
    "            high_rated_urls = [\n",
    "                url for url in urls\n",
    "                if wrapper.context.article_ratings.get(url, 0) >= 0.6\n",
    "            ]\n",
    "            if high_rated_urls:\n",
    "                section_name = topic.title().replace('_', ' ')\n",
    "                sections[section_name] = high_rated_urls\n",
    "\n",
    "        # \"Other News\" section for remaining articles\n",
    "        assigned_urls = set()\n",
    "        for urls in sections.values():\n",
    "            assigned_urls.update(urls)\n",
    "\n",
    "        other_urls = [\n",
    "            url for url in wrapper.context.article_texts.keys()\n",
    "            if url not in assigned_urls and wrapper.context.article_ratings.get(url, 0) >= 0.5\n",
    "        ]\n",
    "\n",
    "        if other_urls:\n",
    "            sections[\"Other News\"] = other_urls\n",
    "\n",
    "        wrapper.context.thematic_sections = sections\n",
    "        wrapper.context.section_names = list(sections.keys())\n",
    "        wrapper.context.current_step = 7\n",
    "\n",
    "        section_summary = \"\\n\".join([\n",
    "            f\"• {name}: {len(urls)} articles\"\n",
    "            for name, urls in sections.items()\n",
    "        ])\n",
    "\n",
    "        return f\"✅ Step 7 Complete: Organized into {len(sections)} sections:\\n{section_summary}\"\n",
    "\n",
    "    @function_tool\n",
    "    async def step8_write_sections(\n",
    "        self,\n",
    "        wrapper: RunContextWrapper[NewsletterState]\n",
    "    ) -> str:\n",
    "        \"\"\"Step 8: Write content for each thematic section\"\"\"\n",
    "        if not wrapper.context.thematic_sections:\n",
    "            return \"❌ No sections to write. Complete steps 1-7 first.\"\n",
    "\n",
    "        section_drafts = {}\n",
    "\n",
    "        for section_name, urls in wrapper.context.thematic_sections.items():\n",
    "            # Gather content for this section\n",
    "            section_articles = []\n",
    "\n",
    "            for url in urls:\n",
    "                summary = wrapper.context.article_summaries.get(url, [])\n",
    "                rating = wrapper.context.article_ratings.get(url, 0)\n",
    "\n",
    "                # Get article title from DataFrame\n",
    "                article_row = wrapper.context.ai_headlines[\n",
    "                    wrapper.context.ai_headlines['url'] == url\n",
    "                ]\n",
    "                title = article_row['title'].iloc[0] if not article_row.empty else \"Unknown Title\"\n",
    "\n",
    "                section_articles.append({\n",
    "                    'title': title,\n",
    "                    'url': url,\n",
    "                    'summary': summary,\n",
    "                    'rating': rating\n",
    "                })\n",
    "\n",
    "            # Write section content (mock implementation)\n",
    "            section_content = f\"## {section_name}\\n\\n\"\n",
    "\n",
    "            for article in sorted(section_articles, key=lambda x: x['rating'], reverse=True):\n",
    "                section_content += f\"**{article['title']}**\\n\"\n",
    "                for bullet in article['summary']:\n",
    "                    section_content += f\"{bullet}\\n\"\n",
    "                section_content += f\"[Read more]({article['url']})\\n\\n\"\n",
    "\n",
    "            section_drafts[section_name] = section_content\n",
    "\n",
    "        wrapper.context.section_drafts = section_drafts\n",
    "        wrapper.context.current_step = 8\n",
    "\n",
    "        return f\"✅ Step 8 Complete: Wrote content for {len(section_drafts)} sections\"\n",
    "\n",
    "    @function_tool\n",
    "    async def step9_finalize_newsletter(\n",
    "        self,\n",
    "        wrapper: RunContextWrapper[NewsletterState],\n",
    "        newsletter_title: str = \"AI Weekly Newsletter\"\n",
    "    ) -> str:\n",
    "        \"\"\"Step 9: Combine sections and polish final newsletter\"\"\"\n",
    "        if not wrapper.context.section_drafts:\n",
    "            return \"❌ No section drafts available. Complete steps 1-8 first.\"\n",
    "\n",
    "        # Combine all sections\n",
    "        newsletter_content = f\"# {newsletter_title}\\n\"\n",
    "        newsletter_content += f\"*Generated on {datetime.now().strftime('%B %d, %Y')}*\\n\\n\"\n",
    "\n",
    "        # Add introduction\n",
    "        total_articles = len(wrapper.context.article_texts)\n",
    "        newsletter_content += f\"This week's AI newsletter covers {total_articles} key developments across {len(wrapper.context.section_drafts)} areas of AI.\\n\\n\"\n",
    "\n",
    "        # Add each section\n",
    "        for section_name in wrapper.context.section_names:\n",
    "            if section_name in wrapper.context.section_drafts:\n",
    "                newsletter_content += wrapper.context.section_drafts[section_name]\n",
    "                newsletter_content += \"\\n---\\n\\n\"\n",
    "\n",
    "        # Add footer\n",
    "        newsletter_content += \"*Thank you for reading! This newsletter was generated using AI curation and analysis.*\"\n",
    "\n",
    "        wrapper.context.final_newsletter = newsletter_content\n",
    "        wrapper.context.workflow_complete = True\n",
    "        wrapper.context.current_step = 9\n",
    "\n",
    "        return f\"✅ Step 9 Complete: Finalized newsletter with {len(wrapper.context.section_drafts)} sections\"\n",
    "\n",
    "    @function_tool\n",
    "    async def get_workflow_status(\n",
    "        self,\n",
    "        wrapper: RunContextWrapper[NewsletterState]\n",
    "    ) -> str:\n",
    "        \"\"\"Get detailed workflow progress status\"\"\"\n",
    "        state = wrapper.context\n",
    "\n",
    "        status = {\n",
    "            'current_step': state.current_step,\n",
    "            'steps_completed': [\n",
    "                f\"1. Scraping: {len(state.raw_headlines)} headlines\" if state.raw_headlines else \"1. Scraping: Pending\",\n",
    "                f\"2. AI Filtering: {len(state.ai_headlines)} AI articles\" if not state.ai_headlines.empty else \"2. AI Filtering: Pending\",\n",
    "                f\"3. Text Fetching: {len(state.article_texts)} articles\" if state.article_texts else \"3. Text Fetching: Pending\",\n",
    "                f\"4. Summarization: {len(state.article_summaries)} summaries\" if state.article_summaries else \"4. Summarization: Pending\",\n",
    "                f\"5. Topic Clustering: {len(state.topic_clusters)} clusters\" if state.topic_clusters else \"5. Topic Clustering: Pending\",\n",
    "                f\"6. Article Rating: {len(state.article_ratings)} rated\" if state.article_ratings else \"6. Article Rating: Pending\",\n",
    "                f\"7. Section Organization: {len(state.thematic_sections)} sections\" if state.thematic_sections else \"7. Section Organization: Pending\",\n",
    "                f\"8. Section Writing: {len(state.section_drafts)} drafts\" if state.section_drafts else \"8. Section Writing: Pending\",\n",
    "                f\"9. Newsletter Finalization: {'Complete' if state.final_newsletter else 'Pending'}\"\n",
    "            ],\n",
    "            'workflow_complete': state.workflow_complete\n",
    "        }\n",
    "\n",
    "        return f\"Newsletter Workflow Status:\\n\\n\" + \"\\n\".join(status['steps_completed'])\n",
    "\n",
    "    @function_tool\n",
    "    async def run_complete_workflow(\n",
    "        self,\n",
    "        wrapper: RunContextWrapper[NewsletterState],\n",
    "        sources: List[str] = None,\n",
    "        ai_keywords: List[str] = None\n",
    "    ) -> str:\n",
    "        \"\"\"Run the complete 9-step workflow automatically\"\"\"\n",
    "        results = []\n",
    "\n",
    "        # Execute each step in sequence\n",
    "        result1 = await self.step1_scrape_headlines(wrapper, sources)\n",
    "        results.append(result1)\n",
    "\n",
    "        result2 = await self.step2_filter_ai_content(wrapper, ai_keywords)\n",
    "        results.append(result2)\n",
    "\n",
    "        result3 = await self.step3_fetch_article_texts(wrapper)\n",
    "        results.append(result3)\n",
    "\n",
    "        result4 = await self.step4_summarize_articles(wrapper)\n",
    "        results.append(result4)\n",
    "\n",
    "        result5 = await self.step5_extract_and_cluster_topics(wrapper)\n",
    "        results.append(result5)\n",
    "\n",
    "        result6 = await self.step6_rate_articles(wrapper)\n",
    "        results.append(result6)\n",
    "\n",
    "        result7 = await self.step7_organize_sections(wrapper)\n",
    "        results.append(result7)\n",
    "\n",
    "        result8 = await self.step8_write_sections(wrapper)\n",
    "        results.append(result8)\n",
    "\n",
    "        result9 = await self.step9_finalize_newsletter(wrapper)\n",
    "        results.append(result9)\n",
    "\n",
    "        newsletter_length = len(wrapper.context.final_newsletter)\n",
    "\n",
    "        return \"\\n\".join(results) + f\"\\n\\n🎉 Complete workflow finished! Newsletter ready ({newsletter_length} characters)\"\n",
    "\n",
    "    @function_tool\n",
    "    async def reset_workflow(\n",
    "        self,\n",
    "        wrapper: RunContextWrapper[NewsletterState]\n",
    "    ) -> str:\n",
    "        \"\"\"Reset workflow to start fresh\"\"\"\n",
    "        wrapper.context.__dict__.update(NewsletterState().__dict__)\n",
    "        return \"🔄 Workflow reset. Ready to start step 1.\"\n",
    "\n",
    "    @function_tool\n",
    "    async def get_newsletter_preview(\n",
    "        self,\n",
    "        wrapper: RunContextWrapper[NewsletterState],\n",
    "        max_chars: int = 500\n",
    "    ) -> str:\n",
    "        \"\"\"Get a preview of the current newsletter\"\"\"\n",
    "        if not wrapper.context.final_newsletter:\n",
    "            return \"Newsletter not ready yet. Complete the full workflow first.\"\n",
    "\n",
    "        preview = wrapper.context.final_newsletter[:max_chars]\n",
    "        if len(wrapper.context.final_newsletter) > max_chars:\n",
    "            preview += \"...\"\n",
    "\n",
    "        return f\"Newsletter Preview:\\n\\n{preview}\"\n",
    "\n",
    "    async def run_step(self, user_input: str) -> str:\n",
    "        \"\"\"Run a workflow step with persistent state\"\"\"\n",
    "        result = await Runner.run(\n",
    "            self,\n",
    "            user_input,\n",
    "            session=self.session,\n",
    "            context=self.state\n",
    "        )\n",
    "        return result.final_output\n",
    "\n",
    "    def save_newsletter(self, filepath: str = None):\n",
    "        \"\"\"Save the final newsletter to file\"\"\"\n",
    "        if not self.state.final_newsletter:\n",
    "            print(\"No newsletter to save. Complete workflow first.\")\n",
    "            return\n",
    "\n",
    "        if filepath is None:\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            filepath = f\"ai_newsletter_{timestamp}.md\"\n",
    "\n",
    "        with open(filepath, 'w') as f:\n",
    "            f.write(self.state.final_newsletter)\n",
    "\n",
    "        print(f\"Newsletter saved to {filepath}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73bb08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "client = openai.OpenAI(\n",
    "  base_url=\"http://localhost:8787/v1\",\n",
    "  api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "  default_headers={\"x-portkey-provider\": \"openai\"}\n",
    ")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[{\"role\": \"user\", \"content\": \"Hello\"}]\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9b37c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from portkey_ai import Portkey\n",
    "\n",
    "client = Portkey(\n",
    "    provider=\"openai\",\n",
    "    Authorization=os.getenv(\"OPENAI_API_KEY\")\n",
    ")\n",
    "\n",
    "# Example: Send a chat completion request\n",
    "response = client.chat.completions.create(\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Hello, how are you?\"}],\n",
    "    model=\"gpt-4o\"\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96cb3bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61793fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    \"\"\"\n",
    "    State of the LangGraph agent.\n",
    "    Each node in the graph is a function that takes the current state and returns the updated state.\n",
    "    \"\"\"\n",
    "\n",
    "    # the current working set of headlines (pandas dataframe not supported)\n",
    "    AIdf: list[dict]\n",
    "    # ignore stories before this date for deduplication (force reprocess since)\n",
    "    model_low: str     # cheap fast model like gpt-4o-mini or flash\n",
    "    model_medium: str  # medium model like gpt-4o or gemini-1.5-pro\n",
    "    model_high: str    # slow expensive thinking model like o3-mini\n",
    "    sources: dict  # sources to scrap\n",
    "    sources_reverse: dict[str, str]  # map file names to sources\n",
    "\n",
    "state = AgentState()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a47b612",
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCES_FILE = \"sources.yaml\"\n",
    "\n",
    "def initialize(state, sources_file=SOURCES_FILE) -> Dict[str, Any]:\n",
    "    \"\"\"Read and parse the sources.yaml file.\"\"\"\n",
    "    try:\n",
    "        with open(sources_file, 'r', encoding='utf-8') as file:\n",
    "            state[\"sources\"] =  yaml.safe_load(file)\n",
    "        state[\"sources_reverse\"] = {v[\"title\"]+\".html\":k for k,v in state[\"sources\"].items()}\n",
    "    except FileNotFoundError:\n",
    "        raise FileNotFoundError(f\"Sources file '{self.sources_file}' not found\")\n",
    "    except yaml.YAMLError as e:\n",
    "        raise ValueError(f\"Error parsing YAML file: {e}\")\n",
    "\n",
    "    return state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4112b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = initialize(state)\n",
    "state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1395fc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "asdk",
   "language": "python",
   "name": "asdk"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
